{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2586b66fff49e70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:16.813108Z",
     "start_time": "2025-06-09T15:25:16.805523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/pycharm_project_377/GPU_32_pythonProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# åˆ¤æ–­æ˜¯å¦åœ¨è¿œç¨‹æœåŠ¡å™¨ç¯å¢ƒ\n",
    "if os.path.exists(\"/home/ubuntu/data/pycharm_project_377\"):\n",
    "# è¿œç¨‹æœåŠ¡å™¨ç¯å¢ƒ\n",
    "    os.chdir(\"/home/ubuntu/data/pycharm_project_377/GPU_32_pythonProject\")\n",
    "    print(os.getcwd())\n",
    "else:\n",
    "# æœ¬åœ°ç¯å¢ƒ\n",
    "#     os.chdir(\"/Users/coyi/PycharmProjects/coyi_pythonProject/\")\n",
    "    os.chdir(\"/Users/coyi/PycharmProjects/coyi_pythonProject/RAG/\")\n",
    "    base_dir=\"/Users/coyi/PycharmProjects/coyi_pythonProject/RAG/\"\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376ffdee8031f545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:17.015242Z",
     "start_time": "2025-06-09T15:25:17.012417Z"
    }
   },
   "outputs": [],
   "source": [
    "# è®¾ç½®openai ä»£ç†\n",
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://api.openai-proxy.org/v1\" # è¿™æ˜¯ä»£ç†ï¼Œå¦‚æœä½ æ˜¯å®˜æ–¹key ï¼Œå°±ä¸è¦è®¾ç½®è¿™ä¸ª\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]   = \"sk-CQI7eRa8J8QBW94nmlSWplqsWqvz6ZwSJ3Xkw1FO9vE2DcUh\" # æ”¹æˆè‡ªå·±çš„key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a70d9e3aabccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:17.202630Z",
     "start_time": "2025-06-09T15:25:17.199699Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# æŒ‡å®š Hugging Face é•œåƒæºä»£ç†\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "# # å¦‚æœä½¿ç”¨ datasets åŒ…ï¼Œå¼€å¯ç¦»çº¿æ¨¡å¼\n",
    "# os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "#\n",
    "# # å¦‚æœä½¿ç”¨ evaluate/metricsï¼Œå¼€å¯ç¦»çº¿æ¨¡å¼\n",
    "# os.environ[\"HF_METRICS_OFFLINE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1412d7d8f728c224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:17.275261Z",
     "start_time": "2025-06-09T15:25:17.270924Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Milvus å‘é‡æ•°æ®åº“ - æœåŠ¡å™¨ç‰ˆç¤ºä¾‹ (Milvus 2.5)\n",
    "# # å®‰è£…ä¾èµ–ï¼š\n",
    "# # pip install -U \"langchain-milvus>=0.1.4\" \"pymilvus>=2.4.3\" \"sentence-transformers\"\n",
    "#\n",
    "# import os, pathlib, time, hashlib, logging\n",
    "# from typing import List\n",
    "#\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.schema import Document\n",
    "# from langchain_milvus import Milvus          # â† å®˜æ–¹æ¨èå®ç°\n",
    "#\n",
    "# # ç¦ç”¨ tokenizers å¹¶è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º INFO\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi(endpoint=\"https://hf-mirror.com\")\n",
    "#\n",
    "# # â”€â”€ 0. è·¯å¾„ & ç¯å¢ƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # ä»¥ä¸‹ä¸¤è¡Œä¿ç•™ï¼Œä»…ä¸ºå…¼å®¹åŸæœ‰é€»è¾‘åˆ›å»ºæœ¬åœ°ç›®å½•ï¼ˆå®é™…æœåŠ¡å™¨æ¨¡å¼ä¸‹æ— éœ€ä½¿ç”¨æ­¤ç›®å½•ï¼‰\n",
    "# BASE = pathlib.Path.cwd() / \"milvus_lite\" / \"prod\"\n",
    "# BASE.mkdir(parents=True, exist_ok=True)\n",
    "# # æœ¬åœ° Lite æ¨¡å¼çš„ URI ä¿ç•™ï¼Œä½†ä¸‹æ–‡ä¸å†ä½¿ç”¨\n",
    "# URI = str(BASE / \"lite.db\")\n",
    "# print(\"Local URI (ä¿ç•™):\", URI)\n",
    "#\n",
    "# # æŒ‡å®š Milvus æœåŠ¡å™¨è¿æ¥å‚æ•°ï¼š\n",
    "# #   host: Milvus server IP æˆ–åŸŸå\n",
    "# #   port: Milvus gRPC ç«¯å£ï¼ˆé»˜è®¤ 19530ï¼‰\n",
    "# MILVUS_CONFIG = {\"host\": \"62.234.111.133\", \"port\": 19530}\n",
    "# COL = \"hybrid_rag\"\n",
    "#\n",
    "# # â”€â”€ 1. ç”Ÿæˆå‘é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # åˆå§‹åŒ–å‘é‡æ¨¡å‹å’Œæ–‡æœ¬åˆ‡åˆ†å™¨ï¼ˆä¸æœ¬åœ°æ¨¡å¼ä¸€è‡´ï¼‰\n",
    "# embed = HuggingFaceEmbeddings(\n",
    "#     model_name=\"BAAI/bge-large-zh-v1.5\",  # å‘é‡æ¨¡å‹åç§°\n",
    "#     cache_folder=\"/home/ubuntu/models\"    # æœ¬åœ°ç¼“å­˜è·¯å¾„\n",
    "# )\n",
    "# split = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=512,                         # æ¯ä¸ªæ–‡æœ¬å—æœ€å¤§é•¿åº¦\n",
    "#     chunk_overlap=64                        # æ–‡æœ¬å—é‡å é•¿åº¦\n",
    "# )\n",
    "#\n",
    "# # texts_source éœ€æå‰å®šä¹‰ä¸ºå¾…ç´¢å¼•æ–‡æœ¬åˆ—è¡¨\n",
    "# # æ„å»ºæ–‡æ¡£åˆ—è¡¨å’Œå¯¹åº”ä¸»é”®\n",
    "# docs, ids = [], []\n",
    "# for i, raw in enumerate(texts_source, 1):\n",
    "#     for chunk in split.split_text(str(raw)):\n",
    "#         # ç”Ÿæˆå†…å®¹æŒ‡çº¹ä½œä¸ºä¸»é”®\n",
    "#         pk = hashlib.md5(chunk.encode()).hexdigest()\n",
    "#         # æ·»åŠ å…ƒæ•°æ®å­—æ®µï¼ˆæ–‡æ¡£IDå’Œæ’å…¥æ—¶é—´æˆ³ï¼‰\n",
    "#         meta = {\"biz_id\": f\"doc_{i}\", \"inserted_at\": int(time.time())}\n",
    "#         docs.append(Document(page_content=chunk, metadata=meta))\n",
    "#         ids.append(pk)\n",
    "#\n",
    "# # â”€â”€ 2. é¦–æ¬¡åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # å¦‚æœé›†åˆä¸å­˜åœ¨ï¼Œåˆ™ä»æ–‡æ¡£æ‰¹é‡åˆ›å»º\n",
    "# # ä½¿ç”¨æœåŠ¡å™¨ç‰ˆè¿æ¥å‚æ•°æ›¿æ¢æœ¬åœ° URI\n",
    "# from_documents_args = {\n",
    "#     \"documents\": docs,\n",
    "#     \"ids\": ids,\n",
    "#     \"embedding\": embed,\n",
    "#     \"collection_name\": COL,\n",
    "#     \"connection_args\": MILVUS_CONFIG,         # â˜… æœåŠ¡å™¨æ¨¡å¼ â˜…\n",
    "#     \"index_params\": {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\"},\n",
    "#     \"auto_id\": False,\n",
    "# }\n",
    "# # æ‰§è¡Œé¦–æ¬¡å†™å…¥\n",
    "# Milvus.from_documents(**from_documents_args)\n",
    "# logging.info(\"INIT âœ å†™å…¥ %s å‘é‡\", len(ids))\n",
    "#\n",
    "# # â”€â”€ 3. å¢é‡åŒæ­¥ (å¹‚ç­‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # æ„å»ºæœåŠ¡å™¨ç‰ˆå®¢æˆ·ç«¯å®ä¾‹\n",
    "# vs = Milvus(\n",
    "#     embedding_function=embed,\n",
    "#     collection_name=COL,\n",
    "#     connection_args=MILVUS_CONFIG,             # â˜… æœåŠ¡å™¨æ¨¡å¼ â˜…\n",
    "#     auto_id=False,\n",
    "# )\n",
    "#\n",
    "# # â¶ åˆ é™¤å¾…åŒæ­¥ä¸»é”®ï¼ˆå³ä½¿ä¸å­˜åœ¨ä¹Ÿæ— é”™è¯¯ï¼‰\n",
    "# vs.delete(ids=ids)\n",
    "# # â· å†ä¸€æ¬¡æ€§æ’å…¥æœ€æ–°ç‰ˆæœ¬ï¼Œå®ç° Upsert æ•ˆæœ\n",
    "# vs.add_documents(docs, ids=ids)\n",
    "#\n",
    "# logging.info(\"SYNC âœ å®Œæˆ %s æ¡ Upsert\", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957d655a56dde859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:23.067322Z",
     "start_time": "2025-06-09T15:25:17.400790Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "milvus_rag_hybrid.py  â€”â€”  ç”µå•†é¢†åŸŸæ··åˆæ£€ç´¢ / é—®ç­” Demo\n",
    "=====================================================\n",
    "æ ¸å¿ƒç‰¹ç‚¹\n",
    "---------\n",
    "1. **å‘é‡ä¾§**ï¼šBGEâ€‘largeâ€‘zhâ€‘v1.5 ç”Ÿæˆç¨ å¯†å‘é‡ï¼ŒMilvus 2.5 é‡Œå»º **HNSW** ç´¢å¼•ã€‚\n",
    "2. **ç¨€ç–ä¾§**ï¼šMilvus 2.5 ã€Œå…¨æ–‡æ£€ç´¢ã€åŠŸèƒ½ï¼Œè‡ªåŠ¨æŠŠ text â†’ sparse_vectorï¼ˆ**BM25**ï¼‰ã€‚\n",
    "3. **æ··åˆå¬å›**ï¼šå‘é‡  +  BM25  ä¸¤è·¯ï¼Œå„å– *k* æ¡åˆå¹¶å»é‡ã€‚\n",
    "4. **é‡æ’**      ï¼šBGE rerankerï¼ˆ`BGERerankFunction`ï¼‰æ‰“åˆ†æŒ‘å‰ *top_n*ã€‚\n",
    "5. **ç­”æ¡ˆç”Ÿæˆ**ï¼šåœ¨çº¿ GPTâ€‘4ï¼ˆå¯æ”¹æœ¬åœ° ChatGLM3ï¼‰ç”Ÿæˆæœ€ç»ˆå›å¤ã€‚\n",
    "6. **å¢é‡å…¥åº“**ï¼š`ingest <folder>` è¯»å–æ–‡ä»¶å¤¹ä¸­ *.txt*ï¼Œå·²å­˜åœ¨ï¼ˆMD5 ä¸»é”®ï¼‰åˆ™è·³è¿‡ã€‚\n",
    "\n",
    "è¿è¡Œå‰å‡†å¤‡\n",
    "-----------\n",
    "::\n",
    "    # â‘   éƒ¨ç½² Milvus 2.5 Standâ€‘aloneï¼ˆDockerï¼‰\n",
    "    docker run -d --name milvus25 \\\n",
    "      -p 19530:19530 -p 9091:9091 \\\n",
    "      -e TZ=Asia/Shanghai \\\n",
    "      -v $PWD/milvus_data:/var/lib/milvus \\\n",
    "      milvusdb/milvus:v2.5.1\n",
    "\n",
    "    # â‘¡  Python ä¾èµ–\n",
    "    python -m pip install -U \\\n",
    "        pymilvus==2.5.* pymilvus-model \\\n",
    "        sentence-transformers \\\n",
    "        openai\n",
    "    # âœ… æ¨¡å‹æƒé‡( BGE / reranker )æå‰ä¸‹è½½å¯åŠ é€Ÿé¦–æ¬¡è¿è¡Œ\n",
    "\n",
    "ç”¨æ³•\n",
    "----\n",
    "::\n",
    "    # æ‰¹é‡å¯¼å…¥ ./docs ç›®å½•ä¸‹çš„ txt æ–‡ä»¶\n",
    "    python milvus_rag_hybrid.py ingest ./docs\n",
    "\n",
    "    # äº¤äº’å¼æé—®\n",
    "    python milvus_rag_hybrid.py ask \"æ¨èå¼•æ“å¸¸ç”¨ç®—æ³•æœ‰å“ªäº›ï¼Ÿ\"\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import getpass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import os, time, hashlib, logging, torch\n",
    "# æ–°ç‰ˆï¼ˆ>=1.0.0ï¼‰æ¨èï¼š\n",
    "from openai import OpenAI\n",
    "from pymilvus import (\n",
    "    MilvusClient, FieldSchema, CollectionSchema, DataType, Function, FunctionType, Collection,connections,utility\n",
    ")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pymilvus.model.dense import SentenceTransformerEmbeddingFunction\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "from sentence_transformers import models  # ä»…ç”¨äºæå‰ä¸‹è½½æƒé‡ï¼Œå¯é€‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaec0bbd2ee15a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:23.284368Z",
     "start_time": "2025-06-09T15:25:23.279694Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# å…¨å±€é…ç½® â€”â€” æ ¹æ®éœ€è¦ä¿®æ”¹\n",
    "# ============================================================================\n",
    "MILVUS_URI = os.getenv(\"MILVUS_URI\", \"127.0.0.1:19530\")\n",
    "COLLECTION_NAME = \"ecommerce_rag\"\n",
    "\n",
    "# â€”â€” åµŒå…¥ / é‡æ’ æ¨¡å‹\n",
    "EMBED_MODEL_NAME = \"BAAI/bge-large-zh-v1.5\"\n",
    "RERANK_MODEL_NAME = \"BAAI/bge-reranker-v2-m3\"\n",
    "# â€”â€” OpenAI\n",
    "## å¯åŠ¨è„šæœ¬æ—¶ï¼Œè‹¥ç¯å¢ƒæ²¡è®¾ï¼Œå°±å¼¹ä¸€æ¬¡è¾“å…¥\n",
    "# å…¨å±€openai clientï¼Œåˆæ¬¡ç”¨æ—¶ç”± ensure_api_key åˆå§‹åŒ–\n",
    "# å…ˆåœ¨ shell ä¸­ export OPENAI_API_KEY=sk-xxx\n",
    "OPENAI_MODEL = \"gpt-4.1-mini-2025-04-14\"\n",
    "client: OpenAI | None = None  # ç¨åç”± ensure_client() åˆå§‹åŒ–\n",
    "# â€”â€” æ£€ç´¢ / é‡æ’ è¶…å‚\n",
    "TOP_K_VECTOR = 50\n",
    "TOP_K_BM25 = 100\n",
    "TOP_N_RERANK = 20\n",
    "MAX_HISTORY = 2  # æœ€è¿‘å¯¹è¯è½®æ•°æ‹¼è¿› promptï¼Œé¿å…è¶…é•¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82c314fe5139a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:23.361056Z",
     "start_time": "2025-06-09T15:25:23.346674Z"
    }
   },
   "outputs": [],
   "source": [
    "# â€”â€” ç¬¬ä¸€æ­¥ï¼šå»ºç«‹é»˜è®¤è¿æ¥ alias\n",
    "# ä»å…¨å±€é…ç½®çš„ MILVUS_URI ä¸­è§£æ host å’Œ port\n",
    "host, port = MILVUS_URI.replace(\"http://\", \"\").replace(\"https://\", \"\").split(\":\")\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=host,\n",
    "    port=port,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2aac4d940e0a8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:26:00.566741Z",
     "start_time": "2025-06-09T15:26:00.560178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Collection `ecommerce_rag` ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤\n"
     ]
    }
   ],
   "source": [
    "# åˆ é™¤æ¨¡å—ï¼Œè°¨æ…æ”¾å¼€ï½ï½ï½\n",
    "from pymilvus import utility\n",
    "\n",
    "# 1. ç¡®è®¤è¿æ¥åˆ«åå’Œ COLLECTION_NAME\n",
    "ALIAS = \"default\"\n",
    "COLLECTION_NAME = \"ecommerce_rag\"\n",
    "\n",
    "# 2. åˆ é™¤æ•´ä¸ª Collectionï¼ˆè¿åŒå®ƒä¸Šé¢çš„æ•°æ®å’Œç´¢å¼•éƒ½ä¼šè¢«æ¸…é™¤ï¼‰\n",
    "if COLLECTION_NAME in utility.list_collections(using=ALIAS):\n",
    "    utility.drop_collection(COLLECTION_NAME, using=ALIAS)\n",
    "    print(f\"âœ… å·²åˆ é™¤ Collection `{COLLECTION_NAME}`\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Collection `{COLLECTION_NAME}` ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b92269261ed9ccba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:23.635718Z",
     "start_time": "2025-06-09T15:25:23.626779Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Milvus â€” Collection ä¿è¯å­˜åœ¨ï¼ˆä¸€æ¬¡æ€§ï¼‰\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_collection() -> Collection:\n",
    "    \"\"\"åœ¨ Milvus ä¸­åˆ›å»ºï¼ˆæˆ–è¿æ¥ï¼‰åä¸º COLLECTION_NAME çš„é›†åˆã€‚\"\"\"\n",
    "    # 1. å»ºç«‹åˆ° Milvus æœåŠ¡çš„è¿æ¥\n",
    "\n",
    "\n",
    "    # 2. æŸ¥è¯¢å½“å‰å·²æœ‰çš„é›†åˆåˆ—è¡¨ï¼Œå¦‚æœ COLLECTION_NAME å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥è¿”å›å¯¹åº”çš„ Collection å¯¹è±¡\n",
    "    #    list_collections() è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯å·²åˆ›å»ºé›†åˆçš„åç§°\n",
    "    if COLLECTION_NAME in utility.list_collections(using=\"default\"):\n",
    "        # Collection() æ¥å—é›†åˆåç§°ï¼Œå°è£…åå¯ä»¥æ‰§è¡Œ insert/search ç­‰æ“ä½œ\n",
    "        return Collection(COLLECTION_NAME, using=\"default\")\n",
    "\n",
    "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "    # 3. å¦‚æœé›†åˆä¸å­˜åœ¨ï¼Œä¸‹é¢å¼€å§‹æ„é€ å®ƒçš„ Schemaï¼ˆé›†åˆç»“æ„ï¼‰å¹¶åˆ›å»º\n",
    "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "    # 3.1 å®šä¹‰å„ä¸ªå­—æ®µï¼ˆFieldï¼‰\n",
    "    fields = [\n",
    "        # æ–‡æ¡£ä¸»é”®â€”â€”ç”¨ MD5 æŒ‡çº¹å­—ç¬¦ä¸²åšå”¯ä¸€æ ‡è¯†\n",
    "        FieldSchema(\n",
    "            name=\"doc_id\",                       # å­—æ®µå\n",
    "            dtype=DataType.VARCHAR,              # å­—ç¬¦ä¸²ç±»å‹\n",
    "            max_length=32,                       # æœ€é•¿ 32 å­—ç¬¦\n",
    "            is_primary=True,                     # ä¸»é”®\n",
    "            auto_id=False                        # ä¸è‡ªåŠ¨ç”Ÿæˆï¼Œéœ€è¦å¤–éƒ¨æä¾›\n",
    "        ),\n",
    "        # åŸå§‹æ–‡æœ¬å­—æ®µï¼Œç”¨äº BM25 å…¨æ–‡æ£€ç´¢\n",
    "        FieldSchema(\n",
    "            name=\"text\",\n",
    "            dtype=DataType.VARCHAR,\n",
    "            max_length=65535,                    # æ”¯æŒå¤§å—æ–‡æœ¬\n",
    "            enable_analyzer=True                 # å¼€å¯åˆ†è¯å™¨ï¼Œæ”¯æŒ BM25 å…¨æ–‡æ£€ç´¢\n",
    "        ),\n",
    "        # ç¨ å¯†å‘é‡å­—æ®µï¼ˆDense Vectorï¼‰ï¼Œç”¨äºè¿‘ä¼¼å‘é‡æœç´¢\n",
    "        FieldSchema(\n",
    "            name=\"dense\",\n",
    "            dtype=DataType.FLOAT_VECTOR,         # æµ®ç‚¹å‘é‡\n",
    "            dim=1024                             # å‘é‡ç»´åº¦ï¼Œä¸ BGE-large-zh-v1.5 è¾“å‡ºçš„å‘é‡ç»´åº¦ä¿æŒä¸€è‡´\n",
    "        ),\n",
    "        # ç¨€ç–å‘é‡å­—æ®µï¼ˆSparse Vectorï¼‰ï¼Œé€šè¿‡å†…ç½® BM25 ç®—å­ç”Ÿæˆ\n",
    "        FieldSchema(\n",
    "            name=\"sparse\",\n",
    "            dtype=DataType.SPARSE_FLOAT_VECTOR,  # ç¨€ç–å‘é‡ç±»å‹\n",
    "            is_function=True                     # è¡¨æ˜æ­¤å­—æ®µç”± Function ç”Ÿæˆ # ç¨€ç–å‘é‡ç”± BM25 ç®—å­è‡ªåŠ¨ç”Ÿæˆ\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # 3.2 æ„é€  CollectionSchemaå¯¹è±¡ï¼Œé™„å¸¦æè¿°ä¿¡æ¯\n",
    "    schema = CollectionSchema(fields, description=\"ç”µå•†é¡¹ç›®æ··åˆæ£€ç´¢ RAG Collection\")\n",
    "\n",
    "    # --- æ³¨å†Œ BM25 å‡½æ•°ç®—å­ ---\n",
    "    # 3.3 # BM25 å‡½æ•°ï¼štext -> sparse\n",
    "    bm25_fn = Function(\n",
    "        name=\"bm25_gen\",                         # ç®—å­åç§°ï¼Œå¯éšæ„å‘½å\n",
    "        input_field_names=[\"text\"],              # è¾“å…¥å­—æ®µï¼šåŸå§‹æ–‡æœ¬\n",
    "        output_field_names=[\"sparse\"],           # è¾“å‡ºå­—æ®µï¼šç¨€ç–å‘é‡\n",
    "        function_type=FunctionType.BM25,         # ç®—å­ç±»å‹ï¼šBM25 å…¨æ–‡æ£€ç´¢\n",
    "    )\n",
    "    # å°†ç®—å­æ³¨å†Œåˆ° schema ä¸­\n",
    "    schema.add_function(bm25_fn)\n",
    "\n",
    "    # 4. åˆ›å»ºé›†åˆï¼šä¼ å…¥é›†åˆåå’Œå®Œæ•´çš„ schema\n",
    "    # ï¼ˆå¿…é¡»æ˜¾å¼æŒ‡å®š schemaï¼‰ï¼š\n",
    "    # # ç›´æ¥ new ä¸€ä¸ª Collectionï¼Œä¼šåœ¨æœåŠ¡ç«¯è‡ªåŠ¨åˆ›å»ºï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰ï¼š\n",
    "    collection = Collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        schema=schema,\n",
    "        using=\"default\" # æŒ‡å®šé“¾æ¥alias \"default\" ä¸‹æ“ä½œ\n",
    "    )\n",
    "\n",
    "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "    # 5. åˆ›å»ºç´¢å¼•ï¼šåˆ†åˆ«å¯¹ç¨ å¯†å’Œç¨€ç–å­—æ®µå»ºç«‹ç´¢å¼•ï¼Œä»¥åŠ é€Ÿæœç´¢\n",
    "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "    # --- HNSW ç´¢å¼•ï¼ˆç”¨äº dense å‘é‡æ£€ç´¢ï¼‰ ---\n",
    "    #   â€¢ Mï¼šæœ€å¤§é‚»å±…æ•°ï¼Œå€¼è¶Šå¤§å¬å›ç‡è¶Šé«˜ä½†æ„å»º/æŸ¥è¯¢é€Ÿåº¦è¶Šæ…¢\n",
    "    #   â€¢ efConstructionï¼šæ„å»ºé˜¶æ®µçš„å€™é€‰åˆ—è¡¨å¤§å°ï¼Œè¶Šå¤§è´¨é‡è¶Šé«˜ä½†è€—æ—¶è¶Šå¤š\n",
    "    # 5.1 å¯¹ dense å‘é‡å­—æ®µåˆ›å»º HNSW ç´¢å¼•ï¼ˆé«˜æ€§èƒ½è¿‘ä¼¼æœç´¢ï¼‰\n",
    "    collection.create_index(\n",
    "        field_name=\"dense\",                                # ç´¢å¼•å­—æ®µ\n",
    "        index_params={\n",
    "            \"index_type\": \"HNSW\",               # ç´¢å¼•ç®—æ³•\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"M\": 16, \"efConstruction\": 200}\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- å€’æ’ç´¢å¼•ï¼ˆç”¨äº sparse BM25 æ£€ç´¢ï¼‰ ---\n",
    "    #   â€¢ SPARSE_INVERTED_INDEXï¼šMilvus å†…ç½®çš„ç¨€ç–å€’æ’ç»“æ„\n",
    "    #   â€¢ metric_type=\"BM25\"ï¼šé‡‡ç”¨ BM25 æ‰“åˆ†æœºåˆ¶\n",
    "    # 5.2 å¯¹ sparse å­—æ®µåˆ›å»ºå€’æ’ç´¢å¼•ï¼Œä½¿ç”¨ BM25 è·ç¦»åº¦é‡\n",
    "    collection.create_index(\n",
    "        field_name=\"sparse\",\n",
    "        index_params={\n",
    "            \"index_type\": \"SPARSE_INVERTED_INDEX\",\n",
    "            \"params\": {\"metric_type\": \"BM25\"}\n",
    "        }\n",
    "    )\n",
    "    # æ¥ä¸‹æ¥æ‰€æœ‰çš„ç´¢å¼•æ“ä½œï¼Œéƒ½ç”¨ col.create_index()\n",
    "    idx_info = collection.indexes  # ORM å±æ€§ï¼ŒæŸ¥çœ‹å·²åˆ›å»ºçš„ç´¢å¼•\n",
    "    if \"dense\" not in {i.field_name for i in idx_info}:\n",
    "        print(\"âŒ dense åˆ›å»ºå¤±è´¥\")\n",
    "    else:\n",
    "        print(\"âœ… dense åˆ›å»ºå®Œæˆ\")\n",
    "    if \"sparse\" not in {i.field_name for i in idx_info}:\n",
    "        print(\"âŒ sparse åˆ›å»ºå¤±è´¥\")\n",
    "    else:\n",
    "        print(\"âœ… sparse åˆ›å»ºå®Œæˆ\")\n",
    "    # æ‰“å°æç¤ºï¼šé›†åˆåˆ›å»ºå®Œæ¯•\n",
    "    print(\"âœ… Collection åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "    # è¿”å›æ–°åˆ›å»ºçš„ Collection å¯¹è±¡ï¼Œåç»­å¯ç›´æ¥ç”¨å®ƒè¿›è¡Œæ’å…¥/æŸ¥è¯¢\n",
    "    return Collection(COLLECTION_NAME, using=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0376fefd47a0b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:33.318926Z",
     "start_time": "2025-06-09T15:25:23.747783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… dense åˆ›å»ºå®Œæˆ\n",
      "âœ… sparse åˆ›å»ºå®Œæˆ\n",
      "âœ… Collection åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# åˆå§‹åŒ–å•ä¾‹ â€”â€” åµŒå…¥ & é‡æ’å‡½æ•°åˆå§‹åŒ– rerank\n",
    "# =============================================================================\n",
    "\n",
    "# 6. å‡†å¤‡å¥½å‘é‡åŒ–å‡½æ•°ï¼šSentenceTransformerEmbeddingFunction\n",
    "#    å°†æ–‡æœ¬æ‰¹é‡è½¬åŒ–ä¸ºç¨ å¯†å‘é‡ï¼Œdevice æ ¹æ®æ˜¯å¦æœ‰ GPU è‡ªåŠ¨é€‰æ‹©\n",
    "EMBED_FN = SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBED_MODEL_NAME,\n",
    "    cache_folder=\"/home/ubuntu/models\",                  # â† æ–°å¢ï¼šæœ¬åœ°æ¨¡å‹ç¼“å­˜è·¯å¾„\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# 7. å‡†å¤‡å¥½é‡æ’å‡½æ•°ï¼šBGE Reranker\n",
    "#    ç”¨äºå¯¹åˆç­›ç»“æœè¿›è¡Œè¿›ä¸€æ­¥æ’åº\n",
    "RERANK_FN = BGERerankFunction(\n",
    "    model_name=RERANK_MODEL_NAME,\n",
    "    cache_folder=\"/home/ubuntu/models\",                  # â† æ–°å¢ï¼šæœ¬åœ°æ¨¡å‹ç¼“å­˜è·¯å¾„\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# 8. åˆ›å»ºæˆ–è·å–é›†åˆâ€”â€”å¹¶èµ‹å€¼ç»™å…¨å±€å˜é‡ COLï¼Œä¾›åç»­ä»£ç ä½¿ç”¨ è·å– Collectionï¼Œå¹¶åŠ è½½\n",
    "COL = ensure_collection()\n",
    "COL.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bebd3143db32a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.221953Z",
     "start_time": "2025-06-09T15:25:33.388192Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œæ‰“å°æ€»é‡\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ‰ å…¨éƒ¨å®Œæˆï¼Œæ–°å¢æ€»è®¡ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_entities)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m æ¡ chunk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mingest_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/data/pycharm_project_377/GPU_32_pythonProject/LLM/é‡æ’rag/test_rag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m, in \u001b[0;36mingest_folder\u001b[0;34m(folder, batch_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 4.1 å‘é‡ç”Ÿæˆï¼šè°ƒç”¨ EMBED_FNï¼Œå¯èƒ½æŠ›é”™\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     vecs \u001b[38;5;241m=\u001b[39m \u001b[43mEMBED_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ å‘é‡ç”Ÿæˆå¤±è´¥ (batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), è·³è¿‡è¯¥æ‰¹æ¬¡: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/pymilvus/model/dense/sentence_transformer.py:32\u001b[0m, in \u001b[0;36mSentenceTransformerEmbeddingFunction.__call__\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39marray]:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/pymilvus/model/dense/sentence_transformer.py:35\u001b[0m, in \u001b[0;36mSentenceTransformerEmbeddingFunction._encode\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39marray]:\n\u001b[0;32m---> 35\u001b[0m     embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_embeddings\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(embs)\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:685\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 685\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    687\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:758\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    757\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    444\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1016\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1016\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1029\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:662\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    651\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    652\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    653\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    659\u001b[0m         output_attentions,\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 662\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    542\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:482\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    474\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    481\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 482\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    492\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:362\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    351\u001b[0m         hidden_states,\n\u001b[1;32m    352\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         output_attentions,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 362\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/dl_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ingest_folder(folder: str, batch_size: int = 1000):\n",
    "    \"\"\"\n",
    "    æŠŠ folder ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶åˆ‡å—åå†™å…¥ Milvusï¼ˆæŒ‰ MD5 å»é‡ï¼‰ã€‚\n",
    "\n",
    "    æ”¹è¿›ç‚¹ï¼š\n",
    "    1. æ‰¹é‡å»é‡ï¼šä¸€æ¬¡æ€§æŸ¥è¯¢æ‰€æœ‰æ–°è®¡ç®—çš„ doc_idï¼Œè€Œä¸æ˜¯æ¯å—å•ç‹¬æŸ¥è¯¢ã€‚\n",
    "    2. åˆ†æ‰¹æ’å…¥ï¼šæŒ‰ batch_size åˆ†æ‰¹ insert + flushï¼Œé¿å…ä¸€æ¬¡æ€§å‹åŠ›è¿‡å¤§ã€‚\n",
    "    3. é”™è¯¯å¤„ç†ï¼šæ•è·å…³é”®æ­¥éª¤å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—å¹¶è·³è¿‡å¤±è´¥éƒ¨åˆ†ã€‚\n",
    "    \"\"\"\n",
    "    # å°†ä¼ å…¥çš„è·¯å¾„å­—ç¬¦ä¸²è½¬ä¸º Path å¯¹è±¡ï¼Œæ–¹ä¾¿åšæ–‡ä»¶ç³»ç»Ÿæ“ä½œ\n",
    "    folder_path = Path(folder)\n",
    "    # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œæå‰è¿”å›\n",
    "    if not folder_path.exists():\n",
    "        print(f\"âŒ ç›®å½•ä¸å­˜åœ¨: {folder}\")\n",
    "        return\n",
    "\n",
    "    # æ–‡æœ¬åˆ‡åˆ†å™¨ï¼šæ¯å— 512 å­—ç¬¦ï¼Œé‡å  64 å­—ç¬¦ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿è´¯\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)\n",
    "\n",
    "    # 1. éå†ç›®å½•ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶ï¼ŒæŠŠæ¯ä¸ªæ–‡ä»¶åˆ‡åˆ†åçš„å—å­˜åˆ° all_chunks åˆ—è¡¨\n",
    "    all_chunks: List[Dict] = []\n",
    "    for txt_file in folder_path.rglob(\"*.txt\"):\n",
    "        # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¿½ç•¥ç¼–ç é”™è¯¯\n",
    "        raw = txt_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        # æŠŠæ•´ä¸ªæ–‡æœ¬åˆ‡æˆå¤šä¸ª chunk\n",
    "        for chunk in splitter.split_text(raw):\n",
    "            # ç”¨ chunk çš„ MD5 ä½œä¸ºå”¯ä¸€ä¸»é”®ï¼Œåé¢ç”¨äºå»é‡\n",
    "            pk = hashlib.md5(chunk.encode()).hexdigest()\n",
    "            # å­˜æˆå­—å…¸ï¼Œåé¢ç»Ÿä¸€æ·»åŠ å‘é‡å­—æ®µå¹¶æ’å…¥\n",
    "            all_chunks.append({\"doc_id\": pk, \"text\": chunk})\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰è¯»åˆ°ä»»ä½•æ–‡æœ¬å—ï¼Œè¯´æ˜æ²¡æœ‰ .txt æˆ–éƒ½ä¸ºç©º\n",
    "    if not all_chunks:\n",
    "        print(\"âš ï¸ æ—  .txt æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º\")\n",
    "        return\n",
    "\n",
    "    # 2. æ‰¹é‡å»é‡ â€”â€” æ„é€ ä¸€ä¸ª Milvus è¡¨è¾¾å¼ï¼ŒæŸ¥è¯¢å·²æœ‰çš„ doc_id\n",
    "    all_pks = [e[\"doc_id\"] for e in all_chunks]\n",
    "    # æ„é€ è¡¨è¾¾å¼ï¼š\"doc_id in ['id1','id2',...]\"\n",
    "    expr = \"doc_id in [\" + \",\".join(f\"'{pk}'\" for pk in all_pks) + \"]\"\n",
    "    try:\n",
    "        existing = COL.query(expr=expr, output_fields=[\"doc_id\"])\n",
    "        existing_pks = {r[\"doc_id\"] for r in existing}\n",
    "    except Exception as e:\n",
    "        # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå°±è·³è¿‡å»é‡ï¼Œå…¨éƒ¨å½“ä½œæ–°æ•°æ®æ’å…¥\n",
    "        print(\"âš ï¸ å»é‡æŸ¥è¯¢å¤±è´¥ï¼Œè·³è¿‡å»é‡\", e)\n",
    "        existing_pks = set()\n",
    "\n",
    "    # 3. ç­›é€‰å‡ºçœŸæ­£éœ€è¦æ’å…¥çš„æ–‡æœ¬å—\n",
    "    new_entities = [e for e in all_chunks if e[\"doc_id\"] not in existing_pks]\n",
    "    if not new_entities:\n",
    "        print(\"âš ï¸ æ— æ–°å¢å†…å®¹\")\n",
    "        return\n",
    "\n",
    "    # 4. åˆ†æ‰¹å¤„ç†æ–°æ•°æ®ï¼šä¸€æ–¹é¢ç”Ÿæˆå‘é‡ï¼Œä¸€æ–¹é¢æ’å…¥ Milvus\n",
    "    for i in range(0, len(new_entities), batch_size):\n",
    "        # å–å‡ºå½“å‰æ‰¹æ¬¡\n",
    "        batch = new_entities[i : i + batch_size]\n",
    "        texts = [e[\"text\"] for e in batch]\n",
    "\n",
    "        # 4.1 å‘é‡ç”Ÿæˆï¼šè°ƒç”¨ EMBED_FNï¼Œå¯èƒ½æŠ›é”™\n",
    "        try:\n",
    "            vecs = EMBED_FN(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å‘é‡ç”Ÿæˆå¤±è´¥ (batch {i//batch_size}), è·³è¿‡è¯¥æ‰¹æ¬¡: {e}\")\n",
    "            continue\n",
    "\n",
    "        # æŠŠç”Ÿæˆçš„ dense å‘é‡æ·»åŠ åˆ°æ¯ä¸ªå®ä½“å­—å…¸ä¸­\n",
    "        # batch æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œåˆå§‹åŒ…å«äº† \"doc_id\" å’Œ \"text\" ä¸¤ä¸ªå­—æ®µ\n",
    "        # æœ€ç»ˆæ‰§è¡Œå®Œåï¼›batch é‡Œçš„æ¯ä¸ªå®ä½“å­—å…¸å°±å˜æˆäº† { \"doc_id\": ..., \"text\": ..., \"dense\": [...] }ï¼Œæ­£å¥½ç¬¦åˆ Milvus æ’å…¥ API è¦æ±‚ã€‚\n",
    "        for e, v in zip(batch, vecs):\n",
    "            e[\"dense\"] = v.tolist()  # è½¬æˆæ™®é€š listï¼Œæ–¹ä¾¿ JSON åºåˆ—åŒ–\n",
    "\n",
    "        # 4.2 æ’å…¥ Milvusï¼Œå¹¶ç«‹å³ flush(è½ç›˜+å¯æŸ¥è¯¢)\n",
    "        try:\n",
    "            COL.insert(batch)\n",
    "            COL.flush()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ’å…¥/åˆ·æ–°å¤±è´¥ (batch {i//batch_size}), è·³è¿‡è¯¥æ‰¹æ¬¡: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"âœ… æˆåŠŸå†™å…¥ batch {i//batch_size}ï¼Œå…± {len(batch)} æ¡\")\n",
    "\n",
    "    # å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œæ‰“å°æ€»é‡\n",
    "    print(f\"ğŸ‰ å…¨éƒ¨å®Œæˆï¼Œæ–°å¢æ€»è®¡ {len(new_entities)} æ¡ chunk\")\n",
    "ingest_folder('/home/ubuntu/data/pycharm_project_377/GPU_32_pythonProject/LLM/é‡æ’rag/test_rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec1f1d699070496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.589579Z",
     "start_time": "2025-06-09T13:41:14.214965Z"
    }
   },
   "outputs": [],
   "source": [
    "def ensure_client():\n",
    "    \"\"\"\n",
    "    ç¡®ä¿å…¨å±€ client å·²åˆå§‹åŒ–ï¼š\n",
    "      1) å¦‚æœç¯å¢ƒå˜é‡é‡Œå·²æœ‰ OPENAI_API_KEYï¼Œç›´æ¥ç”¨å®ƒ\n",
    "      2) å¦åˆ™é€šè¿‡ getpass è¯¢é—®ä¸€æ¬¡ï¼Œå¹¶å†™å›ç¯å¢ƒå˜é‡\n",
    "    ä¹‹ååˆ›å»ºæˆ–æ›´æ–°å…¨å±€ OpenAI(client)\n",
    "    \"\"\"\n",
    "    global client\n",
    "    key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # ä»£ç†åœ°å€\n",
    "    base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai-proxy.org/v1\")\n",
    "    if not key:\n",
    "        # ç¬¬ä¸€æ¬¡æ‰æç¤ºè¾“å…¥\n",
    "        print(f\"âŒ æ²¡æœ‰æ£€æµ‹åˆ°openai key\")\n",
    "        key = getpass.getpass(\"Enter your OpenAI API key: \").strip()\n",
    "        os.environ[\"OPENAI_API_KEY\"] = key\n",
    "    # åˆå§‹åŒ–æ–°ç‰ˆ v1 å®¢æˆ·ç«¯\n",
    "    client = OpenAI(api_key=key,base_url=base_url)\n",
    "    print(f\"âœ… æˆåŠŸåˆå§‹åŒ–client !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a54df02ae2eab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.590914Z",
     "start_time": "2025-06-09T13:41:14.359326Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask(question: str, history: List[str]):\n",
    "    global OPENAI_API_KEY   # â† è¿™ä¸€è¡Œéå¸¸å…³é”® åœ¨å‡½æ•°æœ€å¼€å¤´å£°æ˜\n",
    "    \"\"\"\n",
    "    æ··åˆæ£€ç´¢ + BGE é‡æ’ + GPT-4.1-mini ç”Ÿæˆå›ç­”ã€‚\n",
    "    history ä¸ºä¹‹å‰çš„ç”¨æˆ·é—®é¢˜åˆ—è¡¨ã€‚\n",
    "    å¦‚æœæ²¡æœ‰ç¯å¢ƒå˜é‡ä¸­çš„ API Keyï¼Œä¼šåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶äº¤äº’å¼æç¤ºè¾“å…¥ä¸€æ¬¡ï¼Œ\n",
    "    å¹¶åœ¨åç»­è°ƒç”¨æ—¶è‡ªåŠ¨å¤ç”¨ï¼Œä¸å†é‡å¤è¯¢é—®ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # â€”â€” â‘  ä¸¤è·¯å¬å› â€”â€”\n",
    "    # æŠŠç”¨æˆ·çš„ query è½¬æˆç¨ å¯†å‘é‡ q_vecï¼ˆé•¿åº¦ä¸º 1024ï¼‰ç”¨äºå‘é‡æ£€ç´¢\n",
    "    q_vec = EMBED_FN([question])[0]\n",
    "\n",
    "    # ç”¨ Milvus çš„å‘é‡æ£€ç´¢æ¥å£ï¼Œä» â€œdenseâ€ å­—æ®µä¸­å¬å› TOP_K_VECTOR æ¡æœ€ç›¸ä¼¼çš„å‘é‡æ–‡æ¡£\n",
    "    # metric_type=â€œCOSINEâ€ï¼šæŒ‡å®šç”¨ã€Œä½™å¼¦ç›¸ä¼¼åº¦ã€ä½œä¸ºå‘é‡ä¹‹é—´çš„è·ç¦»åº¦é‡ã€‚\n",
    "    # params={â€œefâ€: TOP_K_VECTOR}ï¼šè¿™æ˜¯ HNSW ç´¢å¼•å†…éƒ¨çš„æœç´¢å‚æ•°â€”â€”efï¼ˆexploration factorï¼‰ã€‚\n",
    "    # ef è¶Šå¤§ï¼Œæœç´¢æ—¶ä¼šæ¢ç´¢æ›´å¤šå€™é€‰èŠ‚ç‚¹ï¼Œå¬å›ç‡æ›´é«˜ä½†é€Ÿåº¦ç¨æ…¢ï¼›é€šå¸¸æŠŠå®ƒè®¾ä¸ºä¸æƒ³è¦è¿”å›çš„ K å€¼ç›¸åŒå¯ä»¥åœ¨æ•ˆç‡å’Œå¬å›ä¹‹é—´å–å¾—å¹³è¡¡ã€‚\n",
    "    vec_hits = COL.search(\n",
    "        data=[q_vec],\n",
    "        anns_field=\"dense\",\n",
    "        param={\"metric_type\": \"COSINE\", \"params\": {\"ef\": TOP_K_VECTOR}},\n",
    "        limit=TOP_K_VECTOR,\n",
    "        output_fields=[\"text\"]           # â† æŠŠ text å­—æ®µå¸¦å›æ¥\n",
    "    )\n",
    "\n",
    "    # ç”¨ Milvus çš„ BM25 å…¨æ–‡æ£€ç´¢æ¥å£ï¼Œä» â€œsparseâ€ å­—æ®µä¸­å¬å› TOP_K_BM25 æ¡æœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "    bm25_hits = COL.search(\n",
    "        data=[question],\n",
    "        anns_field=\"sparse\",\n",
    "        param={},                  # â† è¿™é‡Œä¸èƒ½çœï¼\n",
    "        limit=TOP_K_BM25,\n",
    "        output_fields=[\"text\"]           # â† æŠŠ text å­—æ®µå¸¦å›æ¥\n",
    "    )\n",
    "\n",
    "    # å°†ä¸¤è·¯å¬å›çš„ç»“æœåˆå¹¶å»é‡ï¼ˆç”¨ doc_id åš keyï¼‰ï¼Œåªä¿ç•™ text å­—æ®µ\n",
    "    # python å­—å…¸key å¿…é¡»å”¯ä¸€ï¼šé‡åˆ°é‡å¤çš„ doc_id ä¼šè‡ªåŠ¨åªä¿ç•™æœ€åä¸€æ¬¡å‡ºç°çš„é‚£æ¡\n",
    "    # vec_hits[0] ç¨ å¯†å‘é‡å¬å› å’Œ bm25_hits[0]BM25 ç¨€ç–å¬å› éƒ½æ˜¯åˆ—è¡¨ï¼Œå­˜æ”¾è¿™ä¸€è½®æœç´¢ï¼ˆå¯¹å•ä¸ª queryï¼‰çš„æ‰€æœ‰å‘½ä¸­ç»“æœ\n",
    "    # æ¯ä¸ª hit éƒ½æœ‰ hit.entity.doc_id å’Œ hit.entity.text ä¸¤ä¸ªå±æ€§\n",
    "    pool = {\n",
    "        hit.entity.doc_id: hit.entity.text\n",
    "        for hit in vec_hits[0] + bm25_hits[0]\n",
    "    }\n",
    "    texts = list(pool.values())\n",
    "\n",
    "    # å¦‚æœä¸¤è·¯å¬å›éƒ½æ²¡æœ‰å‘½ä¸­ä»»ä½•æ–‡æ¡£ï¼Œå°±ç›´æ¥è¿”å›æç¤º\n",
    "    if not texts:\n",
    "        return \"(æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£)\"\n",
    "\n",
    "    # â€”â€” â‘¡ é‡æ’ â€”â€”\n",
    "    # è°ƒç”¨ RERANK_FNï¼Œå¯¹å¬å›çš„æ–‡æ¡£ text åˆ—è¡¨æŒ‰ç…§ question åšè¿›ä¸€æ­¥æ‰“åˆ†æ’åº\n",
    "    # rerank_res æ˜¯ä¸€ä¸ªæ‰“åˆ†å¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« text å’Œå¯¹åº”å¾—åˆ†\n",
    "    rerank_res = RERANK_FN(question, texts)\n",
    "\n",
    "    # åªå–é‡æ’åçš„å‰ TOP_N_RERANK æ¡æ–‡æœ¬ï¼Œæ‹¼æˆ prompt çš„ä¸Šä¸‹æ–‡\n",
    "    top_ctx = \"\\n\\n\".join(r.text for r in rerank_res[:TOP_N_RERANK])\n",
    "\n",
    "    # â€”â€” â‘¢ Prompt æ„é€  â€”â€”\n",
    "    # åªä¿ç•™å†å²å¯¹è¯çš„æœ€å MAX_HISTORY è½®ï¼Œç”¨äºæ‹¼æ¥è¿› prompt\n",
    "    #Q1:æˆ‘æƒ³ä¹°æ‰‹æœº\n",
    "    #Q2:æ¨èå“ªäº›å‹å·ï¼Ÿ\n",
    "    short_hist = history[-MAX_HISTORY:]\n",
    "    # æŠŠå†å²å¯¹è¯æ ¼å¼åŒ–æˆ Q1:xxx\\nQ2:xxx çš„å½¢å¼\n",
    "    hist_part = \"\\n\".join(f\"Q{i+1}:{q}\" for i, q in enumerate(short_hist))\n",
    "\n",
    "    # â€”â€” â‘  Systemï¼šè§’è‰² + è¾“å‡ºè§„èŒƒ â€”â€”\n",
    "    system_prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä½ä¸­å›½å¤å…¸æ–‡å­¦ä¸“å®¶ï¼Œç²¾é€šã€Šçº¢æ¥¼æ¢¦ã€‹ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ã€Šæ°´æµ’ä¼ ã€‹ã€Šè¥¿æ¸¸è®°ã€‹ã€‚\\n\"\n",
    "        \"è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹æ ¼å¼ï¼š\\n\\n\"\n",
    "        \"1. å›ç­”ä¸»ä½“ï¼ˆåˆ†ç‚¹ç¼–å·â‘ â‘¡â‘¢â€¦â€¦ï¼‰ï¼Œæ¯ç‚¹æœ«å°¾éƒ½è¦åŠ â€œå¼•ç”¨ï¼š[n]â€ã€‚\\n\"\n",
    "        \"2. å›ç­”ç»“æŸåï¼Œé™„â€œå‚è€ƒæ–‡çŒ®â€åŒºå—ï¼Œåˆ—å‡ºæ¯ä¸ª[n]å¯¹åº”çš„ä¹¦åã€å›ç›®/ç« èŠ‚å’ŒåŸæ–‡ç¤ºä¾‹ã€‚\\n\"\n",
    "        \"3. è‹¥æœ‰å†™ä½œç¤ºä¾‹éœ€æ±‚ï¼Œæ”¾åœ¨å‚è€ƒæ–‡çŒ®ä¹‹åçš„â€œå†™ä½œç¤ºä¾‹â€åŒºå—ã€‚\\n\\n\"\n",
    "        \"â€”â€” Few-Shot ç¤ºä¾‹ â€”â€”\\n\"\n",
    "        \"Q: è‰èˆ¹å€Ÿç®­å‘ç”Ÿåœ¨ä»€ä¹ˆå†å²èƒŒæ™¯ï¼Ÿ\\n\"\n",
    "        \"A:\\n\"\n",
    "        \"â‘  æ—¶é—´ä¸èƒŒæ™¯ï¼šä¸‰å›½èµ¤å£ä¹‹æˆ˜å‰å¤•ï¼Œæ›¹æ“å¤§å†›å—ä¸‹ï¼Œä¸ä¸œå´å½¢æˆå¯¹å³™ã€‚[1]\\n\"\n",
    "        \"â‘¡ è°‹ç•¥æ ¸å¿ƒï¼šè¯¸è‘›äº®åˆ©ç”¨å¤§é›¾ä¸è‰èˆ¹ï¼Œä»æ›¹å†›å¤„â€œå€Ÿâ€å¾—åä¸‡æ”¯ç®­ã€‚[2]\\n\"\n",
    "        \"â‘¢ æ„ä¹‰ä¸å¯ç¤ºï¼šä½“ç°äº†ä»¥é€¸å¾…åŠ³å’Œå¿ƒç†æˆ˜çš„é‡è¦æ€§ã€‚[3]\\n\\n\"\n",
    "        \"å‚è€ƒæ–‡çŒ®ï¼š\\n\"\n",
    "        \"[1] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬äº”åå›â€œè‹¦æˆ˜ä¸ƒæ—¥â€ï¼š\\n\"\n",
    "            \"å›ç›®æ¦‚è¿°ï¼šæœ¬å›è®²è¿°æ›¹æ“ç‡å¤§å†›å—å¾ï¼Œæ²¿æ±Ÿåˆ—è¥ï¼Œä¸å­™æƒã€åˆ˜å¤‡è”å†›å¯¹å³™ï¼›è¯¸è‘›äº®è¢«å‘¨ç‘œè¯•æ¢ï¼Œå¹¶æå‡ºä¸‰æ—¥é€ ç®­ä¹‹éš¾ã€‚  \\n\"\n",
    "            \"åŸæ–‡æ‘˜å½•ï¼š\\n\"\n",
    "            \"â€œæ“å†›äºæŸ´æ¡‘ä¸‹æ±Ÿï¼Œå±¯äºåŒ—å²¸ã€‚â€¦â€¦æ“çŸ¥æ±Ÿæ°´æµæ€¥ï¼Œä¹ƒç­‘æµ®æ¡¥æ¸¡è¥ï¼›åˆæå¤©å¯’å¤±ç²®ï¼Œä¹ƒä½¿äººç´¢è‰äºæ±Ÿä¸Šä¸ºè“‘ï¼Œä¸ºè¡£ï¼Œä»¥å¤‡å¯’æš‘ã€‚å¿½é—»æ±ŸåŒ—çƒ½èµ·ï¼Œä¹ƒæ™“ä¸ºè”å†›å·²è‡³ã€‚æ“ä¹ƒä»¤ç‰™é—¨å°†å­Ÿå¦é•‡å®ˆè¥é—¨ï¼Œäº²ç‡æ•°ä¸‡äººç™»èˆŸå—ä¸‹ã€‚æœªåˆ°å¯¹å²¸ï¼Œåªè§å¯¹å²¸æ—Œæ——è”½æ—¥ï¼Œç«ç„°å†²å¤©å“éœ‡å±±è°·ï¼Œä¸‡ç®­é½å‘å°„æ¥ï¼Œç®­å¦‚é›¨ä¸‹ï¼Œèˆ¹èˆ·å°½è¢«å°„æ»¡ã€‚â€ \\n\"\n",
    "\n",
    "        \"[2] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬äº”åä¸€å›â€œè‰èˆ¹å€Ÿç®­â€ï¼š\\n\"\n",
    "            \"å›ç›®æ¦‚è¿°ï¼šå‘¨ç‘œè®¾ç–‘ï¼Œä»¤è¯¸è‘›äº®ä¸‰æ—¥å†…é€ åä¸‡æ”¯ç®­ï¼›è¯¸è‘›äº®è¿ç”¨å¤§é›¾åŠè‰èˆ¹è®¡ï¼Œå€Ÿå¾—æ›¹è¥ç®­çŸ¢ï¼Œç­”æ ‡éš¾é¢˜ã€‚\\n\"\n",
    "            \"åŸæ–‡æ‘˜å½•ï¼š  \\n\"\n",
    "            \"â€œå­”æ˜ç¬‘æ›°ï¼šâ€˜å†›å¸ˆå‹¿å¿§ï¼Œå¾æœ‰å¦™è®¡ã€‚è¯·å€Ÿå¾äºŒåä¸ˆèˆ¸ï¼Œæ¯èˆ¸ç½®è‰äººç™¾ä½™ï¼Œç´§æŸé’å¸ƒä¸ºå¹”ï¼Œåˆ†å¸ƒä¸¤èˆ·ã€‚ä¸‰æ›´æ—¶åˆ†ï¼Œæœ”é£å°†æ¯ï¼Œé›¾æ°”å¼¥æ¼«ï¼Œå½¼å¿…ç–‘æœ‰äººæ¸¡æ±Ÿï¼Œç®­æ‰‹å¿…å‘æ±Ÿé¢ä¹±å°„ã€‚å±Šæ—¶æ”¶èˆ¹ï¼Œç®­è‡ªæ»¡è½½ã€‚â€™â€¦â€¦æœç„¶å¤§é›¾å››èµ·ï¼Œæ±Ÿé¢èŒ«èŒ«ï¼Œæ›¹å†›è§çŠ¶ï¼Œå¼“å¼©é½å¼€ï¼Œç®­å¦‚é›¨é™ã€‚æ˜æ•™äººå‘½èˆŸå›ï¼Œæ»¡è½½ç®­çŸ¢ä¸ä¸‹åä¸‡ã€‚â€ \\n\"\n",
    "\n",
    "        \"[3] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬äº”åäºŒå›â€œèˆŒæˆ˜ç¾¤å„’â€ï¼š\\n\"\n",
    "            \"å›ç›®æ¦‚è¿°ï¼šèµ¤å£é–æˆ˜å‰ï¼Œè¯¸è‘›äº®äºå­™æƒå¸ä¸‹å·§è¾©ä¸œå´ç¾¤å„’ï¼Œè®ºè¯´è”ç›Ÿåˆ©å®³ï¼ŒåŠ›ä¿ƒå­™åˆ˜åŒå¿ƒã€‚åœºé¢æ°”æ°›ç´§å¼ ï¼Œä¸ºåç»­èµ¤å£ä¹‹æˆ˜å¥ å®šèˆ†è®ºåŸºç¡€ã€‚\\n\"\n",
    "            \"åŸæ–‡æ‘˜å½•ï¼š\\n\"\n",
    "            \"â€œé»„ç›–å–é…’çŒ®ä¸å­”æ˜ï¼Œå­”æ˜èµ·é¢å‰ï¼Œæ‰‹æŒ‡ä¼—å„’æ›°ï¼šâ€˜å¤©åœ°ä¸ä»ï¼Œä»¥ä¸‡ç‰©ä¸ºåˆç‹—ï¼›åŒ¹å¤«å–æ­»ï¼Œä»¥å›½å®¶ä¸ºå„¿æˆã€‚ä»Šæ“æŒŸå¤©å­ä»¥å¾å››æ–¹ï¼Œå¨èµ«ä¸­åŸï¼›å°”æ›¹çŠ¹åœ¨æ­¤å½·å¾¨ï¼Œä½•ä¸é€Ÿä¸è”å†›åˆçºµï¼Ÿâ€™â€¦â€¦å„’ç”Ÿçš†é»˜ï¼Œå…¶å£°éœ‡å½»å½“åœºï¼Œå­™æƒæ‹æ¡ˆç§°å–„ã€‚â€ \\n\\n\"\n",
    "    )\n",
    "\n",
    "    # â€”â€” â‘¡ Assistantï¼šæ³¨å…¥ä¸Šä¸‹æ–‡ â€”â€”\n",
    "    assistant_context = (\n",
    "        \"ã€æ£€ç´¢ä¸Šä¸‹æ–‡ã€‘\\n\"\n",
    "        f\"{top_ctx}\\n\\n\"\n",
    "        \"ã€å¯¹è¯å†å²ã€‘\\n\"\n",
    "        f\"{hist_part}\\n\\n\"\n",
    "        \"â€”â€”\\n\\n\"\n",
    "        \"è¯·åŸºäºä»¥ä¸Šå†…å®¹ï¼Œç”¨â€œâ‘ â‘¡â‘¢â€æ ¼å¼å›ç­”ç”¨æˆ·çš„å½“å‰é—®é¢˜ï¼Œ\"\n",
    "        \"å¹¶åŠ¡å¿…åœ¨æ¯ç‚¹ååŠ â€œå¼•ç”¨ï¼š[n]â€ï¼Œæœ€åç»™å‡ºâ€œå‚è€ƒæ–‡çŒ®â€åˆ—è¡¨ï¼š\"\n",
    "    )\n",
    "\n",
    "    # â€”â€” â‘¢ Userï¼šå½“å‰é—®é¢˜ â€”â€”\n",
    "    user_prompt = question\n",
    "\n",
    "    # â€”â€” â‘£ GPT-4 API â€”â€”\n",
    "    # ä½ çš„ä»£ç†å’Œ API Key å·²ç»é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®å¥½\n",
    "    # â€”â€” 0. ç¡®ä¿ openai client å°±ç»ª â€”â€”\n",
    "    if client is None:\n",
    "        ensure_client()\n",
    "\n",
    "    # è°ƒç”¨ OpenAI ChatCompletion æ¥å£ï¼Œä¼ å…¥åˆšæ‰æ„é€ çš„ prompt\n",
    "    # temperature=0.3 é™ä½éšæœºæ€§ï¼Œè®©å›ç­”æ›´ç¨³å®š\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\",    \"content\": system_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_context},\n",
    "            {\"role\": \"user\",      \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    # ä» API è¿”å›ç»“æœä¸­å–å‡ºç”Ÿæˆçš„å†…å®¹å¹¶å»é™¤å¤šä½™ç©ºç™½åè¿”å›\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abfad71139aa9c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.591118Z",
     "start_time": "2025-06-09T13:41:14.452469Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # åˆ›å»ºä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°è§£æå™¨ï¼Œdescription ç”¨äºåœ¨å¸®åŠ©ä¿¡æ¯ä¸­æ˜¾ç¤ºè„šæœ¬åŠŸèƒ½\n",
    "    parser = argparse.ArgumentParser(description=\"Milvus Hybrid RAG (ä¸­å›½å¤å…¸æ–‡å­¦åŠ©æ‰‹)\")\n",
    "    # æ·»åŠ å­å‘½ä»¤æ”¯æŒï¼Œdest=\"cmd\" è¡¨ç¤ºè§£æåå°†å­å‘½ä»¤åç§°å­˜å…¥ args.cmd\n",
    "    sub = parser.add_subparsers(dest=\"cmd\")\n",
    "\n",
    "    # â€”â€” ingest å­å‘½ä»¤ â€”â€” ç”¨äºå¯¼å…¥æœ¬åœ°æ–‡æœ¬æ–‡ä»¶å¤¹\n",
    "    ing = sub.add_parser(\"ingest\", help=\"å¯¼å…¥æœ¬åœ°æ–‡ä»¶å¤¹\")\n",
    "    # ingest å‘½ä»¤è¦æ¥æ”¶ä¸€ä¸ªä½ç½®å‚æ•° folderï¼Œè¡¨ç¤ºåŒ…å« .txt çš„ç›®å½•è·¯å¾„\n",
    "    ing.add_argument(\"folder\", help=\"åŒ…å« .txt çš„ç›®å½•\")\n",
    "\n",
    "    # â€”â€” ask å­å‘½ä»¤ â€”â€” äº¤äº’å¼æé—®æ¨¡å¼\n",
    "    ask_p = sub.add_parser(\"ask\", help=\"æé—®æ¨¡å¼ (äº¤äº’å¼)\")\n",
    "    # question å‚æ•°å¯é€‰ï¼Œè‹¥æä¾›åˆ™è§†ä¸ºâ€œé¦–ä¸ªé—®é¢˜â€ï¼Œå¦åˆ™ç›´æ¥è¿›å…¥äº¤äº’å¼\n",
    "    ask_p.add_argument(\"question\", nargs=\"?\", help=\"é¦–ä¸ªé—®é¢˜ï¼Œå¯ç©ºè¿›å…¥ interactive\")\n",
    "\n",
    "    # è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    # args = parser.parse_args()\n",
    "    # æ”¹æˆè¿™ä¸€è¡Œï¼Œå¿½ç•¥æœªçŸ¥å‚æ•°\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # å¦‚æœç”¨æˆ·è¾“å…¥çš„æ˜¯ ingest å­å‘½ä»¤\n",
    "    if args.cmd == \"ingest\":\n",
    "        # è°ƒç”¨ ingest_folder å‡½æ•°ï¼Œå°†æŒ‡å®šç›®å½•ä¸­çš„æ–‡æœ¬åˆ‡åˆ†å¹¶å†™å…¥ Milvus\n",
    "        ingest_folder(args.folder)\n",
    "        return  # å¤„ç†å®Œæ¯•åé€€å‡º main\n",
    "\n",
    "    # å¦‚æœç”¨æˆ·è¾“å…¥çš„æ˜¯ ask å­å‘½ä»¤\n",
    "    if args.cmd == \"ask\":\n",
    "        history: List[str] = []  # ç”¨æ¥ä¿å­˜ç”¨æˆ·æé—®çš„å†å²åˆ—è¡¨\n",
    "        # å¦‚æœåœ¨å‘½ä»¤è¡Œä¸­ç»™äº† questionï¼Œå°±å…ˆå›ç­”è¿™ä¸€æ¡\n",
    "        if args.question:\n",
    "            print(ask(args.question, history))\n",
    "            # å°†è¿™æ¬¡æé—®åŠ å…¥å†å²ï¼Œä¸‹æ¬¡ç”Ÿæˆ prompt æ—¶ä¼šç”¨åˆ°\n",
    "            history.append(args.question)\n",
    "        # è¿›å…¥ REPLï¼ˆReadâ€“Evalâ€“Print Loopï¼‰ï¼ŒæŒç»­è¯»å–ç”¨æˆ·è¾“å…¥\n",
    "        try:\n",
    "            while True:\n",
    "                # æç¤ºç”¨æˆ·è¾“å…¥\n",
    "                q = input(\"ä½ : \").strip()\n",
    "                # å¦‚æœè¾“å…¥ä¸ºç©ºï¼Œå¿½ç•¥å¹¶é‡æ–°æç¤º\n",
    "                if not q:\n",
    "                    continue\n",
    "                # è°ƒç”¨ ask() è¿›è¡Œæ£€ç´¢ã€é‡æ’ã€ç”Ÿæˆå›ç­”\n",
    "                ans = ask(q, history)\n",
    "                # æ‰“å° AI å›ç­”\n",
    "                print(\"AI:\", ans)\n",
    "                # ä¿å­˜è¿™æ¬¡æé—®åˆ°å†å²\n",
    "                history.append(q)\n",
    "        # æ•è·ç”¨æˆ·æŒ‰ Ctrl+D æˆ– Ctrl+C çš„é€€å‡ºæ“ä½œ\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\né€€å‡ºå¯¹è¯\")\n",
    "        return  # é€€å‡º main\n",
    "\n",
    "    # å¦‚æœæ—¢ä¸æ˜¯ ingest ä¹Ÿä¸æ˜¯ askï¼Œåˆ™æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯\n",
    "    parser.print_help()\n",
    "\n",
    "\n",
    "# Python è„šæœ¬çš„æ ‡å‡†å†™æ³•ï¼šåªæœ‰å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œæ‰è°ƒç”¨ main()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4fe7f4db75b4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.591225Z",
     "start_time": "2025-06-09T13:41:14.609958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize:   0%|          | 0/1 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 149.58it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåˆå§‹åŒ–client !\n",
      "â‘  ç™½éª¨ç²¾å˜ä½œå­™æ‚Ÿç©ºæ¨¡æ ·ï¼Œå†’å……å­™æ‚Ÿç©ºè¡Œæ¶ï¼Œæ¬ºéª—å”åƒ§ï¼Œå¯¼è‡´å”åƒ§è¯¯ä¼šå­™æ‚Ÿç©ºï¼Œå­™æ‚Ÿç©ºä¸ºä¿æŠ¤å¸ˆçˆ¶å’Œå–ç»é˜Ÿä¼çš„å®‰å…¨ï¼Œå¿…é¡»é™¤æ‰è¿™ä¸ªå¦–ç²¾ä»¥é˜²ç¥¸å®³ã€‚[1]\n",
      "\n",
      "â‘¡ ç™½éª¨ç²¾å…ˆåä¸‰æ¬¡å˜åŒ–ï¼Œä¼å›¾æ³èµ°å”åƒ§ï¼Œå­™æ‚Ÿç©ºè¯†ç ´å…¶ä¼ä¿©ï¼Œå¤šæ¬¡å‡ºæ‰‹æ‰“æ€å¦–ç²¾ï¼Œç»´æŠ¤å–ç»çš„æ­£é“å’Œå¸ˆå¾’å®‰å…¨ï¼Œä½“ç°äº†å­™æ‚Ÿç©ºçš„æœºæ™ºå’Œå¿ è¯šã€‚[1]\n",
      "\n",
      "â‘¢ å­™æ‚Ÿç©ºæ‰“ç™½éª¨ç²¾è™½è¢«å”åƒ§è¯¯è§£ä¸ºæ»¥æ€æ— è¾œï¼Œä½†å®é™…ä¸Šæ˜¯ä¸ºäº†ä¿æŠ¤å¸ˆçˆ¶å’Œå–ç»å¤§ä¸šï¼Œæ˜¾ç¤ºå‡ºå­™æ‚Ÿç©ºå¯¹å¸ˆçˆ¶çš„å¿ å¿ƒå’Œå¯¹å¦–é­”çš„åšå†³æ–—äº‰æ€åº¦ã€‚[1]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š  \n",
      "[1] ã€Šè¥¿æ¸¸è®°ã€‹ç¬¬äº”åä¸ƒå›â€œå­™è¡Œè€…ä¸‰æ‰“ç™½éª¨ç²¾â€ï¼š  \n",
      "å›ç›®æ¦‚è¿°ï¼šç™½éª¨ç²¾ä¸‰æ¬¡å˜åŒ–æ¬ºéª—å”åƒ§ï¼Œå­™æ‚Ÿç©ºè¯†ç ´å¹¶ä¸‰æ¬¡æ‰“æ€å¦–ç²¾ï¼Œè™½è¢«å”åƒ§è¯¯è§£ï¼Œä½†æœ€ç»ˆæ­ç©¿å¦–ç²¾çœŸé¢ç›®ã€‚  \n",
      "åŸæ–‡æ‘˜å½•ï¼š  \n",
      "â€œæˆ‘å› ä¿æŠ¤å”åƒ§å¾€è¥¿å¤©å–ç»åœ¨è·¯ä¸Šæ‰“æ€è´¼å¾’ï¼Œé‚£ä¸‰è—èµ¶æˆ‘å›å»ï¼Œæˆ‘å¾„åˆ°æ™®é™€å´–è§è§‚éŸ³è©è¨è¯‰è‹¦ï¼Œä¸æƒ³è¿™å¦–ç²¾å‡ æ—¶å°±å˜ä½œæˆ‘çš„æ¨¡æ ·ï¼Œæ‰“å€’å”åƒ§æŠ¢å»åŒ…è¢±â€¦â€¦åŸæ¥è¿™å¦–ç²¾æœè±¡è€å­™æ¨¡æ ·ï¼Œæ‰è‡ªæ°´å¸˜æ´æ‰“åˆ°æ™®é™€å±±è§è©è¨ï¼Œè©è¨ä¹Ÿéš¾è¯†è®¤ï¼Œæ•…æ‰“è‡³æ­¤é—´çƒ¦è¯¸å¤©çœ¼åŠ›ä¸æˆ‘è®¤ä¸ªçœŸå‡ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"å­™æ‚Ÿç©ºä¸ºä»€ä¹ˆæ‰“ç™½éª¨ç²¾ï¼Ÿï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6e68311953e632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.606465Z",
     "start_time": "2025-06-09T13:41:21.369591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 178.09it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  å®¶æ—åˆ©ç›Šä¸å©šå§»å®‰æ’çš„å†²çªï¼šè´¾å®ç‰ä¸æ—é»›ç‰çš„çˆ±æƒ…è¢«å®¶æ—çš„åˆ©ç›Šå’Œå©šå§»å®‰æ’æ‰€å·¦å³ã€‚è–›å®é’—çš„å‡ºç°ï¼Œä½œä¸ºå®¶æ—è®¤å¯çš„é—¨å½“æˆ·å¯¹çš„å©šé…å¯¹è±¡ï¼Œä½“ç°äº†å°å»ºå®¶æ—å¯¹å©šå§»çš„åŠŸåˆ©æ€§è€ƒé‡ï¼Œä¸ªäººæ„Ÿæƒ…å¾€å¾€è¢«ç‰ºç‰²ã€‚[1]\n",
      "\n",
      "â‘¡ ç¤¾ä¼šèº«ä»½ä¸ç¤¼æ•™æŸç¼šï¼šå®ç‰è™½æ€§æƒ…çº¯çœŸï¼Œä½†èº«å¤„å°å»ºç¤¼æ•™ä¸¥æ ¼çš„ç¤¾ä¼šç¯å¢ƒä¸­ï¼Œå¿…é¡»éµå®ˆå®¶æ—çš„è§„çŸ©å’Œç¤¾ä¼šçš„ç­‰çº§ç§©åºã€‚å®ç‰çš„æ‡’æ•£å’Œåå›ï¼Œå®é™…ä¸Šæ˜¯å¯¹è¿™ç§æŸç¼šçš„æ— å£°æŠ—è®®ï¼Œä½†æœ€ç»ˆéš¾ä»¥é€ƒè„±å‘½è¿çš„å®‰æ’ã€‚[2]\n",
      "\n",
      "â‘¢ å¥³æ€§å‘½è¿çš„æ‚²å‰§ä½“ç°ï¼šæ—é»›ç‰çš„å¤šæ„å–„æ„Ÿå’Œä½“å¼±å¤šç—…ï¼Œè±¡å¾ç€å°å»ºç¤¾ä¼šä¸­å¥³æ€§çš„è„†å¼±ä¸æ— å¥ˆã€‚å¥¹åœ¨å®¶æ—å’Œç¤¾ä¼šçš„åŒé‡å‹åŠ›ä¸‹ï¼Œæ— æ³•å®ç°è‡ªæˆ‘ä»·å€¼å’Œå¹¸ç¦ï¼Œæœ€ç»ˆæˆä¸ºçˆ±æƒ…æ‚²å‰§çš„ç‰ºç‰²å“ã€‚[3]\n",
      "\n",
      "â‘£ å®¶æ—å†…éƒ¨çŸ›ç›¾ä¸æƒ…æ„Ÿç–ç¦»ï¼šè´¾åºœå†…éƒ¨è™½è¡¨é¢ç¹åï¼Œä½†äº²æƒ…å…³ç³»å¤æ‚ï¼Œå®ç‰ä¸é»›ç‰çš„äº²å¯†ä¹Ÿå¤¹æ‚ç€å«‰å¦’å’Œè¯¯è§£ï¼Œåæ˜ äº†å°å»ºå®¶æ—å†…éƒ¨çš„çŸ›ç›¾å’Œæƒ…æ„Ÿçš„ç–ç¦»ï¼Œå¢åŠ äº†æ‚²å‰§çš„æ·±åº¦ã€‚[4]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š  \n",
      "[1] ã€Šçº¢æ¥¼æ¢¦ã€‹ç¬¬äº”å›â€œæ¸¸å¹»å¢ƒæŒ‡è¿·åäºŒé’—â€åŠç›¸å…³ç« èŠ‚ï¼šè–›å®é’—çš„å…¥åºœåŠå…¶ä¸é»›ç‰çš„å¯¹æ¯”ï¼Œå®¶æ—å¯¹å©šå§»çš„å®‰æ’ã€‚  \n",
      "[2] ã€Šçº¢æ¥¼æ¢¦ã€‹ç¬¬ä¸ƒå›â€œé€å®«èŠ±è´¾çæˆç†™å‡¤â€åŠç›¸å…³æå†™ï¼šå®ç‰çš„æ€§æ ¼ä¸å®¶æ—è§„çŸ©çš„å†²çªã€‚  \n",
      "[3] ã€Šçº¢æ¥¼æ¢¦ã€‹ç¬¬åä¸‰å›â€œç§¦å¯å¿æ­»å°é¾™ç¦å°‰â€åŠç›¸å…³ç« èŠ‚ï¼šé»›ç‰çš„ä½“å¼±å¤šç—…å’Œå¥³æ€§å‘½è¿çš„æå†™ã€‚  \n",
      "[4] ã€Šçº¢æ¥¼æ¢¦ã€‹ç¬¬ä¸‰å›â€œè´¾å®ç‰ç¥æ¸¸å¤ªè™šå¢ƒâ€åŠç›¸å…³ç« èŠ‚ï¼šè´¾åºœå†…éƒ¨å¤æ‚çš„äººé™…å…³ç³»å’Œæƒ…æ„Ÿçº è‘›ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"è´¾å®ç‰ä¸æ—é»›ç‰çš„çˆ±æƒ…æ‚²å‰§åæ˜ äº†æ€æ ·çš„ç¤¾ä¼šç°å®ä¸å®¶æ—å‹åŠ›ï¼Ÿï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dbd5822df23c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.606823Z",
     "start_time": "2025-06-09T13:41:27.902924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 176.01it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  å®‹æ±Ÿåœ¨æ¢å±±å¥½æ±‰ä¸­è¢«ç§°ä¸ºâ€œåŠæ—¶é›¨â€ã€‚è¿™ä¸€ç»°å·æºäºä»–ä¹äºåŠ©äººã€è¡Œä¾ ä»—ä¹‰çš„æ€§æ ¼ï¼Œåƒæ˜¥é›¨åŠæ—¶æ»‹æ¶¦å¤§åœ°ï¼Œå¸®åŠ©æœ‰éš¾çš„äººã€‚[1]\n",
      "\n",
      "â‘¡ æ­¤å¤–ï¼Œå®‹æ±Ÿä¹Ÿè¢«ç§°ä¸ºâ€œå‘¼ä¿ä¹‰â€ï¼Œæ„ä¸ºâ€œå·å¬ä¹‰æ°”â€ï¼Œä½“ç°äº†ä»–åœ¨æ¢å±±å¥½æ±‰ä¸­çš„é¢†å¯¼åœ°ä½å’Œå·å¬åŠ›ã€‚[2]\n",
      "\n",
      "â‘¢ åœ¨ã€Šæ°´æµ’ä¼ ã€‹ä¸­ï¼Œå®‹æ±Ÿçš„ç»°å·å¤šæ¬¡è¢«æåŠï¼Œæ˜¾ç¤ºäº†ä»–åœ¨æ±Ÿæ¹–ä¸Šçš„å£°æœ›å’Œäººç¼˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¢å±±æ³Šèšä¹‰æ—¶ï¼Œä¼—å¥½æ±‰å¯¹ä»–çš„å°Šæ•¬ã€‚[3]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š  \n",
      "[1] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬ä¸‰å›â€œåŠæ—¶é›¨å®‹æ±Ÿæ€æƒœâ€  \n",
      "å›ç›®æ¦‚è¿°ï¼šä»‹ç»å®‹æ±Ÿçš„ç»°å·â€œåŠæ—¶é›¨â€åŠå…¶ä¹å–„å¥½æ–½çš„æ€§æ ¼ã€‚  \n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œå®‹æ±Ÿï¼Œå­—å…¬æ˜ï¼Œéƒ“åŸå¿éƒ“åŸå¿äººæ°ï¼Œç»°å·â€˜åŠæ—¶é›¨â€™ï¼Œå› ä»–é‡äº‹åŠæ—¶ç›¸åŠ©ï¼Œæ•…å¾—æ­¤åã€‚â€  \n",
      "\n",
      "[2] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬å››å›â€œæ—æ•™å¤´é£é›ªå±±ç¥åº™â€  \n",
      "å›ç›®æ¦‚è¿°ï¼šå®‹æ±Ÿè¢«ç§°ä¸ºâ€œå‘¼ä¿ä¹‰â€ï¼Œæ„æŒ‡å·å¬ä¹‰æ°”ï¼Œè¡¨ç°å…¶é¢†å¯¼æ‰èƒ½ã€‚  \n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œå‘¼ä¿ä¹‰å®‹æ±Ÿï¼Œä¹‰æ°”æ·±é‡ï¼Œä¼—å¥½æ±‰çš†æ•¬ä»°ä¹‹ã€‚â€  \n",
      "\n",
      "[3] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬ä¸ƒå›â€œæŸ´è¿›å°èšä¹‰â€  \n",
      "å›ç›®æ¦‚è¿°ï¼šæ¢å±±å¥½æ±‰èšä¹‰ï¼Œä¼—äººç§°å®‹æ±Ÿä¸ºâ€œåŠæ—¶é›¨â€ï¼Œå½°æ˜¾å…¶å¨æœ›ã€‚  \n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œä¼—å¥½æ±‰è§å®‹æ±Ÿï¼Œé½å£°å‘¼ä½œâ€˜åŠæ—¶é›¨â€™ï¼Œçš†æ„Ÿå…¶æ©å¾·ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"å®‹æ±Ÿåœ¨æ¢å±±å¥½æ±‰ä¸­è¢«ç§°ä½œä»€ä¹ˆç»°å·ï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ead826abfc0035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607080Z",
     "start_time": "2025-06-09T13:41:33.810095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 174.98it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  æ—¶é—´èƒŒæ™¯ï¼šè‰èˆ¹å€Ÿç®­å‘ç”Ÿåœ¨ä¸‰å›½æ—¶æœŸï¼Œèµ¤å£ä¹‹æˆ˜å‰å¤•ï¼Œæ›¹æ“ç‡å¤§å†›å—ä¸‹ï¼Œä¸å­™æƒã€åˆ˜å¤‡è”å†›å½¢æˆå¯¹å³™å±€é¢ã€‚[1]\n",
      "\n",
      "â‘¡ å†›äº‹å¯¹å³™ï¼šæ›¹æ“å¤§å†›åœ¨é•¿æ±ŸåŒ—å²¸å¸ƒé˜²ï¼Œå­™åˆ˜è”å†›åœ¨æ±Ÿå—å¯¹å³™ã€‚å‘¨ç‘œä¸ºè¯•æ¢è¯¸è‘›äº®ï¼Œå‘½å…¶ä¸‰æ—¥å†…é€ åä¸‡æ”¯ç®­ï¼Œæ„å›¾éš¾å€’è¯¸è‘›äº®ã€‚[1]\n",
      "\n",
      "â‘¢ äº‹ä»¶ç»è¿‡ï¼šè¯¸è‘›äº®åˆ©ç”¨å¤§é›¾å¤©æ°”ï¼Œå€ŸåŠ©é²è‚ƒçš„èˆ¹åªï¼Œè£…æ»¡è‰äººå’Œé’å¸ƒå¹”ï¼Œé è¿‘æ›¹è¥æ°´å¯¨ï¼Œè¯±ä½¿æ›¹å†›å¼“å¼©æ‰‹ä¹±ç®­å°„æ¥ï¼ŒæˆåŠŸâ€œå€Ÿâ€å¾—åä¸‡ä½™æ”¯ç®­ï¼Œè§£å†³äº†ç®­çŸ¢ä¸è¶³çš„éš¾é¢˜ã€‚[1]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š\n",
      "[1] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬å››åå…­å›â€œç”¨å¥‡è°‹å­”æ˜å€Ÿç®­ çŒ®å¯†è®¡é»„ç›–å—åˆ‘â€ï¼š\n",
      "å›ç›®æ¦‚è¿°ï¼šæœ¬å›è®²è¿°è¯¸è‘›äº®å—å‘¨ç‘œè¯•æ¢ï¼Œä¸‰æ—¥å†…é€ ç®­éš¾é¢˜ï¼›è¯¸è‘›äº®å·§ç”¨å¤§é›¾å’Œè‰èˆ¹è®¡ï¼ŒæˆåŠŸä»æ›¹å†›å¤„å€Ÿå¾—åä¸‡æ”¯ç®­ï¼Œå±•ç°å…¶ç¥æœºå¦™ç®—ã€‚\n",
      "åŸæ–‡æ‘˜å½•ï¼š\n",
      "â€œè‚ƒé¢†å‘½æ¥è§å­”æ˜ã€‚å­”æ˜æ›°ï¼šâ€˜å¾æ›¾å‘Šå­æ•¬ï¼Œä¼‘å¯¹å…¬ç‘¾è¯´ï¼Œä»–å¿…è¦å®³æˆ‘ã€‚ä¸æƒ³å­æ•¬ä¸è‚¯ä¸ºæˆ‘éšè®³ï¼Œä»Šæ—¥æœç„¶åˆå¼„å‡ºäº‹æ¥ã€‚ä¸‰æ—¥å†…å¦‚ä½•é€ å¾—åä¸‡ç®­ï¼Ÿå­æ•¬åªå¾—æ•‘æˆ‘ï¼â€™â€¦â€¦ç¬¬ä¸‰æ—¥å››æ›´æ—¶åˆ†ï¼Œå­”æ˜å¯†è¯·é²è‚ƒåˆ°èˆ¹ä¸­â€¦â€¦æ˜¯å¤œå¤§é›¾æ¼«å¤©ï¼Œé•¿æ±Ÿä¹‹ä¸­ï¼Œé›¾æ°”æ›´ç”šâ€¦â€¦æ›¹å¯¨ä¸­ï¼Œå¬å¾—æ“‚é¼“å‘å–Šâ€¦â€¦å¼“å¼©é½å¼€ï¼Œç®­å¦‚é›¨é™â€¦â€¦å­”æ˜ä»¤æ”¶èˆ¹æ€¥å›â€¦â€¦èˆ¹ä¸¤è¾¹æŸè‰ä¸Šï¼Œæ’æ»¡ç®­æâ€¦â€¦å­”æ˜æ•™äºèˆ¹ä¸Šå–ä¹‹ï¼Œå¯å¾—åä½™ä¸‡æã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"è‰èˆ¹å€Ÿç®­â€å‘ç”Ÿåœ¨ä»€ä¹ˆå†å²èƒŒæ™¯å’Œå†›äº‹å¯¹å³™ä¸­ï¼Ÿï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "986be364c9377abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607231Z",
     "start_time": "2025-06-09T13:41:38.630090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 160.90it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  èµ¤å£ä¹‹æˆ˜çš„å‘ç”ŸåŸå› ä¸»è¦æ˜¯æ›¹æ“ç»Ÿä¸€åŒ—æ–¹åï¼Œæ„å›¾å—ä¸‹å¾æœæ±Ÿä¸œå­™æƒå’Œåˆ˜å¤‡ï¼Œæ‰©å¤§å…¶ç»Ÿæ²»èŒƒå›´ã€‚æ›¹æ“æŒŸå¤©å­ä»¥ä»¤è¯¸ä¾¯ï¼Œå¨åŠ¿æ—¥ç››ï¼Œå¨èƒæ±Ÿä¸œæ”¿æƒçš„å®‰å…¨ï¼Œå­™æƒå’Œåˆ˜å¤‡ä¸ºæŠ—è¡¡æ›¹æ“çš„å¼ºå¤§å†›åŠ›ï¼Œè”åˆæŠµæŠ—ï¼Œå½¢æˆäº†ä¸‰æ–¹å¯¹å³™çš„å±€é¢ã€‚[1]\n",
      "\n",
      "â‘¡ æˆ˜äº‰çˆ†å‘çš„ç›´æ¥å¯¼ç«ç´¢æ˜¯æ›¹æ“ç‡é¢†å¤§å†›å—ä¸‹ï¼Œä¼å›¾é€šè¿‡æ°´é™†å¹¶è¿›çš„æ–¹å¼å¿«é€Ÿæ”»å æ±Ÿä¸œã€‚å­™æƒåœ¨æƒè¡¡åˆ©å¼Šåï¼Œå†³å®šè”åˆåˆ˜å¤‡ï¼Œå…±åŒæŠµå¾¡æ›¹æ“çš„è¿›æ”»ã€‚å‘¨ç‘œç­‰å´å°†ç§¯æå¤‡æˆ˜ï¼Œç­‘åé˜²å®ˆï¼Œå‡†å¤‡è¿æˆ˜æ›¹æ“çš„æ°´å†›ã€‚[2]\n",
      "\n",
      "â‘¢ èµ¤å£ä¹‹æˆ˜çš„ç»“æœæ˜¯æ›¹æ“å¤§è´¥ï¼Œæ°´å†›è¢«å‘¨ç‘œç«æ”»çƒ§æ¯ï¼Œæ›¹æ“è¢«è¿«æ’¤é€€ï¼Œæ±Ÿä¸œå’Œè†å·æš‚æ—¶å¾—ä»¥ä¿å…¨ã€‚æ­¤æˆ˜å¥ å®šäº†ä¸‰å›½é¼ç«‹çš„åŸºç¡€ï¼Œå­™æƒç¨³å›ºæ±Ÿä¸œï¼Œåˆ˜å¤‡å¾—ä»¥æ‰©å±•è†å·ï¼Œå½¢æˆé­ã€èœ€ã€å´ä¸‰å›½é¼ç«‹çš„å±€é¢ï¼Œå½±å“äº†ä¸­å›½å†å²çš„èµ°å‘ã€‚[3]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š\n",
      "[1] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬ä¸ƒåä¸ƒå›â€œç«çƒ§èµ¤å£â€ï¼š\n",
      "å›ç›®æ¦‚è¿°ï¼šè®²è¿°æ›¹æ“æŒŸå¤©å­å—å¾ï¼Œå­™åˆ˜è”å†›æŠ—å‡»æ›¹å†›ï¼Œèµ¤å£å¤§æˆ˜çˆ†å‘çš„èƒŒæ™¯ã€‚\n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œæ›¹æ“æŒŸå¤©å­ä»¥å¾å››æ–¹ï¼Œå¨èµ«ä¸­åŸâ€¦â€¦å­™æƒå¤§æ€’ï¼Œå•†è®®èµ·å†›æ”»å–è†å·â€¦â€¦å¿½æŠ¥æ›¹æ“èµ·å†›å››åä¸‡æ¥æŠ¥èµ¤å£ä¹‹ä»‡ã€‚â€\n",
      "\n",
      "[2] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬ä¸ƒåå…«å›â€œå‘¨ç‘œæ€’æ€ç¨‹æ™®â€ï¼š\n",
      "å›ç›®æ¦‚è¿°ï¼šå­™æƒå‘½ä»¤ç­‘æ¿¡é¡»åé˜²å¾¡æ›¹æ“ï¼Œå‘¨ç‘œç­‰å°†é¢†ç§¯æå¤‡æˆ˜ã€‚\n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œæƒæ›°ï¼šâ€˜äººæ— è¿œè™‘ï¼Œå¿…æœ‰è¿‘å¿§ã€‚å­æ˜ä¹‹è§ç”šè¿œã€‚â€™ä¾¿å·®å†›æ•°ä¸‡ç­‘æ¿¡é¡»åã€‚æ™“å¤œå¹¶å·¥ï¼Œåˆ»æœŸå‘Šç«£ã€‚â€\n",
      "\n",
      "[3] ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ç¬¬ä¸ƒåä¹å›â€œç«çƒ§è¿è¥â€ï¼š\n",
      "å›ç›®æ¦‚è¿°ï¼šèµ¤å£å¤§æˆ˜æ›¹æ“å¤§è´¥ï¼Œå‘¨ç‘œç«æ”»ç ´æ›¹å†›ï¼Œä¸‰å›½é¼ç«‹æ ¼å±€åˆç°ã€‚\n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œä¸‰æ±Ÿæ°´æˆ˜ï¼Œèµ¤å£é–å…µã€‚æ›¹å†›ç€æªä¸­ç®­ã€ç«ç„šæ°´æººè€…ï¼Œä¸è®¡å…¶æ•°â€¦â€¦èµ¤å£é—é›„çƒˆï¼Œé’å¹´æœ‰ä¿Šå£°â€¦â€¦å·´ä¸˜ç»ˆå‘½å¤„ï¼Œå‡­åŠæ¬²ä¼¤æƒ…ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"èµ¤å£ä¹‹æˆ˜çš„å‘ç”ŸåŸå› ä¸æˆ˜åæ ¼å±€å¦‚ä½•ï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1140590f3618f474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607342Z",
     "start_time": "2025-06-09T13:41:44.772648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 168.88it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  å­™æ‚Ÿç©ºå¤§é—¹å¤©å®«ï¼ŒçŠ¯äº†â€œè¯³ä¸Šä¹‹ç½ªâ€ï¼Œå³è¿æŠ—å¤©åº­æ³•ä»¤ï¼Œæ‰°ä¹±å¤©å®«ç§©åºï¼Œè§¦çŠ¯äº†å¤©æ¡ï¼Œå› æ­¤è¢«å¦‚æ¥ä½›ç¥–é•‡å‹ã€‚[1]\n",
      "\n",
      "â‘¡ å­™æ‚Ÿç©ºå› å…¶æ¡€éªœä¸é©¯ï¼Œæ›¾å¤šæ¬¡æŒ‘æˆ˜å¤©åº­æƒå¨ï¼Œç”šè‡³è‡ªç§°â€œé½å¤©å¤§åœ£â€ï¼Œå¼•èµ·å¤©åº­éœ‡æ€’ï¼Œæœ€ç»ˆå¦‚æ¥ä½›ç¥–ç”¨æ³•åŠ›å°†å…¶å‹äºäº”è¡Œå±±ä¸‹ï¼Œä»¥ç¤ºæƒ©æˆ’å’Œçº¦æŸã€‚[1]\n",
      "\n",
      "â‘¢ äº”è¡Œå±±æ˜¯å¦‚æ¥ä½›ç¥–ç”¨äº”æŒ‡åŒ–ä½œçš„äº”åº§è”å±±ï¼Œè½»è½»å‹ä½å­™æ‚Ÿç©ºï¼Œé˜²æ­¢å…¶å†è¡Œä½œä¹±ï¼ŒåŒæ—¶ä¹Ÿæ˜¯å¯¹å…¶æœªæ¥çšˆä¾ä½›æ³•çš„è€ƒéªŒå’Œçº¦æŸã€‚[1]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š  \n",
      "[1] ã€Šè¥¿æ¸¸è®°ã€‹ç¬¬åå››å›â€œå¿ƒçŒ¿å½’æ­£ï¼Œäº”è¡Œå±±ä¸‹å®šé£æ³¢â€ï¼š  \n",
      "å›ç›®æ¦‚è¿°ï¼šè®²è¿°å­™æ‚Ÿç©ºå¤§é—¹å¤©å®«åï¼Œè¢«å¦‚æ¥ä½›ç¥–é•‡å‹äºäº”è¡Œå±±ä¸‹ï¼Œç­‰å¾…æœ‰ç¼˜äººè§£æ•‘ã€‚  \n",
      "åŸæ–‡æ‘˜å½•ï¼š  \n",
      "â€œå¥½å¤§åœ£æ€¥çºµèº«åˆè¦è·³å‡ºè¢«ä½›ç¥–ç¿»æŒä¸€æ‰‘æŠŠè¿™çŒ´ç‹æ¨å‡ºè¥¿å¤©é—¨å¤–å°†äº”æŒ‡åŒ–ä½œé‡‘ã€æœ¨ã€æ°´ã€ç«ã€åœŸäº”åº§è”å±±è½»è½»çš„æŠŠä»–å‹ä½ã€‚â€  \n",
      "â€œå½“å¹´åµåŒ–å­¦ä¸ºäººç«‹å¿—ä¿®è¡Œæœé“çœŸã€‚ä¸‡åŠ«æ— ç§»å±…èƒœå¢ƒä¸€æœæœ‰å˜æ•£ç²¾ç¥ã€‚æ¬ºå¤©ç½”ä¸Šæ€é«˜ä½å‡Œåœ£å·ä¸¹ä¹±å¤§ä¼¦ã€‚æ¶è´¯æ»¡ç›ˆä»Šæœ‰æŠ¥ä¸çŸ¥ä½•æ—¥å¾—ç¿»èº«ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"å­™æ‚Ÿç©ºä¸ºä½•ç¬¬ä¸€æ¬¡è¢«å‹äºäº”è¡Œå±±ä¸‹ï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351c4e1d21399f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607447Z",
     "start_time": "2025-06-09T13:41:50.209839Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 171.71it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  å¥³æ€§å‘½è¿çš„å¤šæ ·æ€§ä¸æ‚²å‰§æ€§ï¼šã€Šçº¢æ¥¼æ¢¦ã€‹ä¸­çš„â€œé‡‘é™µåäºŒé’—â€ä¸ä»…æ˜¯ç¾è²Œå¥³å­çš„é›†åˆï¼Œæ›´æ˜¯å„å…·æ€§æ ¼ã€å‘½è¿è¿¥å¼‚çš„å¥³æ€§ç¾¤åƒã€‚å¥¹ä»¬æˆ–å¯Œè´µæˆ–è´«è´±ï¼Œæˆ–æ¸©æŸ”æˆ–åˆšçƒˆï¼Œå‘½è¿å¤šèˆ›ï¼Œä½“ç°äº†å°å»ºç¤¾ä¼šå¥³æ€§åœ¨å®¶æ—å…´è¡°ã€ç¤¾ä¼šå˜è¿ä¸­çš„æ— å¥ˆä¸æŒ£æ‰ã€‚[1]\n",
      "\n",
      "â‘¡ æ—¶ä»£èƒŒæ™¯ä¸‹çš„å¥³æ€§å›°å¢ƒï¼šè¿™äº›å¥³æ€§å¤§å¤šç”Ÿäºæœ«ä¸–è¿åæ¶ˆçš„æ—¶ä»£ï¼Œèº«å¤„å®¶æ—è¡°è´¥ã€ç¤¾ä¼šåŠ¨è¡çš„ç¯å¢ƒä¸­ï¼Œè™½æœ‰æ‰æƒ…ä¸ç¾è²Œï¼Œå´éš¾é€ƒå‘½è¿çš„æ‰å¼„å’Œç¤¾ä¼šçš„å‹è¿«ï¼Œåæ˜ äº†å°å»ºç¤¼æ•™å¯¹å¥³æ€§çš„æŸç¼šå’Œæ—¶ä»£å˜è¿å¸¦æ¥çš„å†²å‡»ã€‚[2]\n",
      "\n",
      "â‘¢ æƒ…æ„Ÿä¸ç†æƒ³çš„çŸ›ç›¾å†²çªï¼šé‡‘é™µåäºŒé’—ä¸­çš„å¥³æ€§å¤šæƒ…è€Œå¤šæ„Ÿï¼Œå†…å¿ƒä¸°å¯Œå´å¸¸è¢«ç°å®æ‰€é™åˆ¶ã€‚å¥¹ä»¬çš„çˆ±æƒ…ã€å‹æƒ…å’Œäº²æƒ…äº¤ç»‡ï¼Œæ—¢æœ‰æ¸©æŸ”å’Œé¡ºï¼Œä¹Ÿæœ‰åæŠ—å’ŒæŒ£æ‰ï¼Œè¡¨ç°äº†ä¸ªäººæƒ…æ„Ÿä¸ç¤¾ä¼šä¼¦ç†ã€å®¶æ—è´£ä»»ä¹‹é—´çš„çŸ›ç›¾ã€‚[3]\n",
      "\n",
      "â‘£ é€šè¿‡ç¾¤åƒå±•ç°ç¤¾ä¼šé£è²Œä¸äººæ€§å¤æ‚ï¼šæ›¹é›ªèŠ¹å€ŸåäºŒé’—çš„ä¸åŒå‘½è¿ï¼ŒæŠ˜å°„å‡ºå½“æ—¶ç¤¾ä¼šçš„é£æ°”ã€äººæƒ…å†·æš–ä»¥åŠäººæ€§çš„å–„æ¶ç¾ä¸‘ï¼Œæ—¢æœ‰å¯¹ç¾å¥½å“å¾·çš„æ­Œé¢‚ï¼Œä¹Ÿæœ‰å¯¹è™šä¼ªå¥¸ä½çš„æ‰¹åˆ¤ï¼Œä½“ç°äº†æ·±åˆ»çš„ç¤¾ä¼šæ‰¹åˆ¤ç²¾ç¥å’Œäººæ–‡å…³æ€€ã€‚[4]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š\n",
      "[1] ã€Šçº¢æ¥¼æ¢¦ã€‹â€œé‡‘é™µåäºŒé’—æ­£å†Œâ€åŠâ€œåˆå‰¯å†Œâ€ç« èŠ‚ï¼š\n",
      "å›ç›®æ¦‚è¿°ï¼šæç»˜åäºŒä½ä¸»è¦å¥³æ€§å½¢è±¡ï¼Œæ­ç¤ºå…¶å„è‡ªçš„æ€§æ ¼ä¸å‘½è¿æ‚²æ¬¢ã€‚\n",
      "åŸæ–‡æ‘˜å½•ï¼šâ€œæ»¡çº¸è’å”è¨€ï¼Œä¸€æŠŠè¾›é…¸æ³ªï¼éƒ½äº‘ä½œè€…ç—´ï¼Œè°è§£å…¶ä¸­å‘³ï¼Ÿâ€  \n",
      "[2] ã€Šçº¢æ¥¼æ¢¦ã€‹â€œåˆå‰¯å†Œâ€ä¸­å…³äºå¥³æ€§å‘½è¿çš„è¯—å¥ï¼š\n",
      "â€œæ‰è‡ªç²¾æ˜å¿—è‡ªé«˜ï¼Œç”Ÿäºæœ«ä¸–è¿åæ¶ˆã€‚â€  \n",
      "â€œå¯Œè´µåˆä½•ä¸ºï¼Œè¥è¤“ä¹‹é—´çˆ¶æ¯è¿ã€‚â€  \n",
      "[3] ã€Šçº¢æ¥¼æ¢¦ã€‹å…³äºé‡‘æ¡‚ä¸é¦™è±çš„å¯¹è¯åŠæå†™ï¼š\n",
      "â€œå®é’—ä¹…å¯Ÿå…¶ä¸è½¨ä¹‹å¿ƒï¼Œæ¯éšæœºåº”å˜ï¼Œæš—ä»¥è¨€è¯­å¼¹å‹å…¶å¿—ã€‚â€  \n",
      "â€œé¦™è±çš†ç­”å¿˜è®°ï¼Œé‡‘æ¡‚ä¾¿ä¸æ‚¦ï¼Œè¯´æœ‰æ„æ¬ºç’äº†ä»–ã€‚â€  \n",
      "[4] ã€Šçº¢æ¥¼æ¢¦ã€‹å¯¹å¥³æ€§ç¾¤åƒçš„ç¤¾ä¼šæ‰¹åˆ¤ä¸äººæ€§æå†™ï¼š\n",
      "â€œè™½å…¶ä¸­å¤§æ—¨è°ˆæƒ…ï¼Œäº¦ä¸è¿‡å®å½•å…¶äº‹ï¼Œåˆéå‡æ‹Ÿå¦„ç§°ï¼Œä¸€å‘³æ·«é‚€è‰³çº¦ï¼Œç§è®¢å·ç›Ÿä¹‹å¯æ¯”ï¼å› æ¯«ä¸å¹²æ¶‰æ—¶ä¸–ï¼Œæ–¹ä»å¤´è‡³å°¾æŠ„å½•å›æ¥ï¼Œé—®ä¸–ä¼ å¥‡ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"æ›¹é›ªèŠ¹å€Ÿâ€œé‡‘é™µåäºŒé’—â€ç¾¤åƒæƒ³è¦ä¼ è¾¾å“ªäº›å¥³æ€§å‘½è¿ä¸æ—¶ä»£ä¸»é¢˜ï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f41fe5328e02e226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607578Z",
     "start_time": "2025-06-09T13:41:56.339877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 169.73it/s]\n",
      "Compute Scores: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â‘  åˆæœŸèšé›†ï¼šæ¢å±±æ³Šæœ€åˆæ˜¯ç”±æ™ç›–ç­‰äººèµ·ä¹‰èšé›†ï¼Œæ™ç›–è¢«æ¨ä¸¾ä¸ºå±±å¯¨é¦–é¢†ï¼Œå´ç”¨ä¸ºå†›å¸ˆï¼Œå…¬å­™èƒœæŒå†›æƒã€‚å„è·¯è‹±é›„å¥½æ±‰é™†ç»­æŠ•å¥”æ¢å±±ï¼Œå½¢æˆäº†æœ€åˆçš„éª¨å¹²åŠ›é‡ã€‚[1]\n",
      "\n",
      "â‘¡ ç»“ä¹‰èª“ç›Ÿï¼šå®‹æ±Ÿç­‰ä¸€ç™¾é›¶å…«ä½å¥½æ±‰åœ¨æ¢å±±å¿ ä¹‰å ‚ä¸Šä¸¾è¡Œç››å¤§èšä¹‰ï¼Œç„šé¦™èª“ç›Ÿï¼Œç«‹ä¸‹â€œæ›¿å¤©è¡Œé“ï¼Œä¿å¢ƒå®‰æ°‘â€çš„å¤§ä¹‰èª“è¨€ï¼Œèª“æ­»åŒç”Ÿå…±æ­»ï¼Œå¿ ä¹‰ç›¸æ‰¶ï¼Œå½¢æˆåšä¸å¯æ‘§çš„å…„å¼Ÿæƒ…è°Šã€‚[2]\n",
      "\n",
      "â‘¢ ç»„ç»‡å®Œå–„ä¸æ‰©å……ï¼šæ™ç›–ç­‰å¤´é¢†å®‰æ’å¯¨å†…äº‹åŠ¡ï¼Œä¿®ç­‘å¯¨æ …ï¼Œæ•´é¡¿å†›å¤‡ï¼Œæ‹›å‹Ÿæ›´å¤šè‹±é›„å¥½æ±‰ï¼Œé€æ­¥æ‰©å¤§é˜Ÿä¼è§„æ¨¡ï¼Œå½¢æˆä¸€ç™¾é›¶å…«å°†çš„å®Œæ•´é˜µå®¹ï¼Œæ¶µç›–å„è¡Œå„ä¸šï¼Œå—åŒ—ä¸œè¥¿ï¼Œè´µè´±ä¸åˆ†ï¼ŒçœŸæ­£å®ç°äº†â€œå¼‚å§“ä¸€å®¶â€çš„å…„å¼Ÿæƒ…è°Šã€‚[3]\n",
      "\n",
      "å‚è€ƒæ–‡çŒ®ï¼š  \n",
      "[1] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬ä¸‰å›â€œå²å¤§éƒå¤œèµ°åé˜´å¿â€åŠç¬¬å››å›â€œæ—æ•™å¤´é£é›ªå±±ç¥åº™â€  \n",
      "åŸæ–‡æ‘˜å½•ï¼šæ™ç›–ç­‰äººèµ·ä¹‰ï¼Œèšé›†æ¢å±±ï¼Œæ¨ä¸¾æ™ç›–ä¸ºé¦–é¢†ï¼Œå´ç”¨ä¸ºå†›å¸ˆï¼Œå…¬å­™èƒœæŒå†›æƒã€‚  \n",
      "[2] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬ä¸ƒå›â€œæ—å†²é›ªå¤œä¸Šæ¢å±±â€  \n",
      "åŸæ–‡æ‘˜å½•ï¼šå®‹æ±Ÿç­‰ä¸€ç™¾é›¶å…«äººäºæ¢å±±å¿ ä¹‰å ‚ä¸Šç„šé¦™èª“ç›Ÿï¼Œç«‹ä¸‹æ›¿å¤©è¡Œé“çš„èª“è¨€ï¼Œèª“æ­»åŒç”Ÿå…±æ­»ã€‚  \n",
      "[3] ã€Šæ°´æµ’ä¼ ã€‹ç¬¬å…«å›â€œæé€µé—¹æ±Ÿå·â€  \n",
      "åŸæ–‡æ‘˜å½•ï¼šæ™ç›–ç­‰å¤´é¢†å®‰æ’å¯¨å†…äº‹åŠ¡ï¼Œä¿®ç­‘å¯¨æ …ï¼Œæ•´é¡¿å†›å¤‡ï¼Œæ‹›å‹Ÿè‹±é›„ï¼Œå½¢æˆä¸€ç™¾é›¶å…«å°†çš„å®Œæ•´é˜µå®¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"æ¢å±±æ³Šçš„ä¸€ç™¾é›¶å…«å°†æ˜¯å¦‚ä½•é€æ­¥èšé›†å¹¶ç»“ä¸ºå…„å¼Ÿçš„ï¼Ÿ\", []) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8c5ccd0814d3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T15:25:49.607736Z",
     "start_time": "2025-06-09T13:42:05.169953Z"
    }
   },
   "outputs": [],
   "source": [
    "# ä»¥ä¸‹æ˜¯ 20 æ¡é’ˆå¯¹ä¸­å›½å¤å…¸å››å¤§åè‘—ï¼ˆã€Šçº¢æ¥¼æ¢¦ã€‹ã€Šè¥¿æ¸¸è®°ã€‹ã€Šæ°´æµ’ä¼ ã€‹ã€Šä¸‰å›½æ¼”ä¹‰ã€‹ï¼‰çš„æµ‹è¯•é—®é¢˜ï¼Œæ¯éƒ¨ 5 æ¡ï¼Œæ–¹ä¾¿æ‚¨æ£€éªŒç³»ç»Ÿï¼š\n",
    "#\n",
    "# ã€Šçº¢æ¥¼æ¢¦ã€‹æµ‹è¯•é—®é¢˜\n",
    "# \t1.\tã€Šçº¢æ¥¼æ¢¦ã€‹çš„å‰å…«åå›ä¸åå››åå›åˆ†åˆ«èšç„¦å“ªäº›äººç‰©å‘½è¿ä¸å®¶æ—å…´è¡°ï¼Ÿ\n",
    "# \t2.\tè´¾å®ç‰ä¸æ—é»›ç‰çš„çˆ±æƒ…æ‚²å‰§åæ˜ äº†æ€æ ·çš„ç¤¾ä¼šç°å®ä¸å®¶æ—å‹åŠ›ï¼Ÿ\n",
    "# \t3.\tè–›å®é’—åœ¨å¤§è§‚å›­ä¸­æ‰®æ¼”äº†æ€æ ·çš„â€œç†æ€§â€ä¸â€œå’Œäº‹ä½¬â€è§’è‰²ï¼Ÿ\n",
    "# \t4.\tâ€œå¤§è§‚å›­â€åœ¨ä½œå“ä¸­è±¡å¾ç€æ€æ ·çš„ç¹åä¸è™šå¹»ï¼Ÿ\n",
    "# \t5.\tæ›¹é›ªèŠ¹å€Ÿâ€œé‡‘é™µåäºŒé’—â€ç¾¤åƒæƒ³è¦ä¼ è¾¾å“ªäº›å¥³æ€§å‘½è¿ä¸æ—¶ä»£ä¸»é¢˜ï¼Ÿ\n",
    "#\n",
    "# ã€Šè¥¿æ¸¸è®°ã€‹æµ‹è¯•é—®é¢˜  ï¿¼\n",
    "# \t1.\tã€Šè¥¿æ¸¸è®°ã€‹çš„å…¬è®¤ä½œè€…é€šå¸¸æ˜¯è°ï¼Ÿ  ï¿¼\n",
    "# \t2.\tå­™æ‚Ÿç©ºä¸ºä½•ç¬¬ä¸€æ¬¡è¢«å‹äºäº”è¡Œå±±ä¸‹ï¼Ÿ  ï¿¼\n",
    "# \t3.\tå”åƒ§å—å¤©ç«ºå–ç»çš„æ ¸å¿ƒç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ  ï¿¼\n",
    "# \t4.\tâ€œå–ç»å››äººç»„â€ç”±å“ªäº›äººç‰©ç»„æˆï¼Ÿ  ï¿¼\n",
    "# \t5.\tã€Šè¥¿æ¸¸è®°ã€‹å±äºå“ªç§å°è¯´ä½“è£ï¼Ÿ  ï¿¼\n",
    "#\n",
    "# ã€Šæ°´æµ’ä¼ ã€‹æµ‹è¯•é—®é¢˜\n",
    "# \t1.\tã€Šæ°´æµ’ä¼ ã€‹çš„ä½œè€…ä¸€èˆ¬è¢«è®¤ä¸ºæ˜¯è°ï¼Ÿ\n",
    "# \t2.\tæ¢å±±æ³Šçš„ä¸€ç™¾é›¶å…«å°†æ˜¯å¦‚ä½•é€æ­¥èšé›†å¹¶ç»“ä¸ºå…„å¼Ÿçš„ï¼Ÿ\n",
    "# \t3.\tå®‹æ±Ÿåœ¨æ¢å±±å¥½æ±‰ä¸­è¢«ç§°ä½œä»€ä¹ˆç»°å·ï¼Ÿ\n",
    "# \t4.\tâ€œæ›¿å¤©è¡Œé“â€è¿™ä¸€å£å·åœ¨å°è¯´ä¸­ä½“ç°äº†æ€æ ·çš„ä»·å€¼è§‚ï¼Ÿ\n",
    "# \t5.\tã€Šæ°´æµ’ä¼ ã€‹é€šè¿‡æ¢å±±å¥½æ±‰å½¢è±¡æ‰¹åˆ¤äº†å“ªäº›ç¤¾ä¼šçŸ›ç›¾ï¼Ÿ\n",
    "#\n",
    "# ã€Šä¸‰å›½æ¼”ä¹‰ã€‹æµ‹è¯•é—®é¢˜\n",
    "# \t1.\tã€Šä¸‰å›½æ¼”ä¹‰ã€‹çš„ä½œè€…æ˜¯è°ï¼Ÿ\n",
    "# \t2.\tâ€œè‰èˆ¹å€Ÿç®­â€å‘ç”Ÿåœ¨ä»€ä¹ˆå†å²èƒŒæ™¯å’Œå†›äº‹å¯¹å³™ä¸­ï¼Ÿ\n",
    "# \t3.\tæ¡ƒå›­ä¸‰ç»“ä¹‰è±¡å¾äº†æ€æ ·çš„å…„å¼Ÿæƒ…è°Šä¸å¿ ä¹‰ç²¾ç¥ï¼Ÿ\n",
    "# \t4.\tæ›¹æ“â€œæŒŸå¤©å­ä»¥ä»¤è¯¸ä¾¯â€ä½“ç°äº†ä½•ç§æ”¿æ²»ç­–ç•¥ï¼Ÿ\n",
    "# \t5.\tèµ¤å£ä¹‹æˆ˜çš„å‘ç”ŸåŸå› ä¸æˆ˜åæ ¼å±€å¦‚ä½•ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
